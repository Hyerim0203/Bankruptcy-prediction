{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP를 이용한 부도예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 및 train, valid, test set 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_valid(file_name, valid=True):\n",
    "    raw = pd.read_csv(f\"{data_path}/{file_name}\")\n",
    "    \n",
    "    # 데이터셋 분할\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train_valid, X_test, y_train_valid, y_test = train_test_split(raw.iloc[:,:-1],raw.iloc[:,-1],\n",
    "                                                       random_state = 1)\n",
    "    \n",
    "    if valid:\n",
    "        X_train,X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size = 0.2,\n",
    "                                                            random_state = 1)\n",
    "\n",
    "        # 표준화\n",
    "        from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "        scaler = MinMaxScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_valid = scaler.transform(X_valid)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        return X_train,X_valid,X_test,y_train,y_valid,y_test\n",
    "    else:\n",
    "         # 표준화\n",
    "        from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "        scaler = MinMaxScaler().fit(X_train_valid)\n",
    "        X_train_valid = scaler.transform(X_train_valid)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        return X_train_valid, X_test, y_train_valid, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 초기화 설정\n",
    "lucun_init = keras.initializers.VarianceScaling(scale=2.,\n",
    "                                mode=\"fan_in\",distribution=\"truncated_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_score(X_test, y_test, term,model):\n",
    "    predicted = model.predict((X_test, X_test[:,-10*term:])).round()\n",
    "    accuracy = accuracy_score(y_test, predicted)\n",
    "    precision = precision_score(y_test,predicted)\n",
    "    recall = recall_score(y_test, predicted)\n",
    "    confusion = confusion_matrix(y_test, predicted)\n",
    "    roc = roc_auc_score(y_test, predicted)\n",
    "    return accuracy, precision, recall, confusion, roc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클래스 개수의 균형 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.882135\n",
       "1    0.117865\n",
       "Name: CR, dtype: float64"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()/y_train.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 년도별 accuracy, recall, precision, roc 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1630 - accuracy: 0.6615 - val_loss: 1.1242 - val_accuracy: 0.2214\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 0.1525 - accuracy: 0.2209 - val_loss: 1.0802 - val_accuracy: 0.2545\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1442 - accuracy: 0.2522 - val_loss: 0.8348 - val_accuracy: 0.4582\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1297 - accuracy: 0.4462 - val_loss: 0.6263 - val_accuracy: 0.6605\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1231 - accuracy: 0.6605 - val_loss: 0.5301 - val_accuracy: 0.7473\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1203 - accuracy: 0.7435 - val_loss: 0.5202 - val_accuracy: 0.7518\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1141 - accuracy: 0.7503 - val_loss: 0.5642 - val_accuracy: 0.7114\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1069 - accuracy: 0.7166 - val_loss: 0.6340 - val_accuracy: 0.6636\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1025 - accuracy: 0.6677 - val_loss: 0.6882 - val_accuracy: 0.6350\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1006 - accuracy: 0.6410 - val_loss: 0.6920 - val_accuracy: 0.6355\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0983 - accuracy: 0.6444 - val_loss: 0.6454 - val_accuracy: 0.6645\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0947 - accuracy: 0.6767 - val_loss: 0.5737 - val_accuracy: 0.7045\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0913 - accuracy: 0.7183 - val_loss: 0.5059 - val_accuracy: 0.7445\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0894 - accuracy: 0.7524 - val_loss: 0.4602 - val_accuracy: 0.7773\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0885 - accuracy: 0.7748 - val_loss: 0.4419 - val_accuracy: 0.7859\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0875 - accuracy: 0.7832 - val_loss: 0.4485 - val_accuracy: 0.7832\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0858 - accuracy: 0.7798 - val_loss: 0.4735 - val_accuracy: 0.7668\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0841 - accuracy: 0.7682 - val_loss: 0.5063 - val_accuracy: 0.7459\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0830 - accuracy: 0.7551 - val_loss: 0.5330 - val_accuracy: 0.7355\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0824 - accuracy: 0.7447 - val_loss: 0.5413 - val_accuracy: 0.7332\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0818 - accuracy: 0.7433 - val_loss: 0.5276 - val_accuracy: 0.7400\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0808 - accuracy: 0.7511 - val_loss: 0.4980 - val_accuracy: 0.7600\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0796 - accuracy: 0.7641 - val_loss: 0.4639 - val_accuracy: 0.7764\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0786 - accuracy: 0.7797 - val_loss: 0.4357 - val_accuracy: 0.7905\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0780 - accuracy: 0.7915 - val_loss: 0.4199 - val_accuracy: 0.7991\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0775 - accuracy: 0.7975 - val_loss: 0.4183 - val_accuracy: 0.8005\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0767 - accuracy: 0.7991 - val_loss: 0.4287 - val_accuracy: 0.7955\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0757 - accuracy: 0.7974 - val_loss: 0.4459 - val_accuracy: 0.7895\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0749 - accuracy: 0.7916 - val_loss: 0.4622 - val_accuracy: 0.7818\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0744 - accuracy: 0.7863 - val_loss: 0.4700 - val_accuracy: 0.7800\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0739 - accuracy: 0.7842 - val_loss: 0.4653 - val_accuracy: 0.7845\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0732 - accuracy: 0.7853 - val_loss: 0.4495 - val_accuracy: 0.7927\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0725 - accuracy: 0.7929 - val_loss: 0.4287 - val_accuracy: 0.8032\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0719 - accuracy: 0.8015 - val_loss: 0.4104 - val_accuracy: 0.8105\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0714 - accuracy: 0.8097 - val_loss: 0.3997 - val_accuracy: 0.8164\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0710 - accuracy: 0.8146 - val_loss: 0.3987 - val_accuracy: 0.8164\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0705 - accuracy: 0.8153 - val_loss: 0.4061 - val_accuracy: 0.8136\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0700 - accuracy: 0.8124 - val_loss: 0.4175 - val_accuracy: 0.8082\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0695 - accuracy: 0.8085 - val_loss: 0.4269 - val_accuracy: 0.8032\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0692 - accuracy: 0.8052 - val_loss: 0.4290 - val_accuracy: 0.8027\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0689 - accuracy: 0.8048 - val_loss: 0.4223 - val_accuracy: 0.8068\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0685 - accuracy: 0.8078 - val_loss: 0.4097 - val_accuracy: 0.8114\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0681 - accuracy: 0.8137 - val_loss: 0.3967 - val_accuracy: 0.8186\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0678 - accuracy: 0.8196 - val_loss: 0.3884 - val_accuracy: 0.8227\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0675 - accuracy: 0.8238 - val_loss: 0.3872 - val_accuracy: 0.8259\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0672 - accuracy: 0.8252 - val_loss: 0.3925 - val_accuracy: 0.8241\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0669 - accuracy: 0.8229 - val_loss: 0.4007 - val_accuracy: 0.8200\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0666 - accuracy: 0.8204 - val_loss: 0.4069 - val_accuracy: 0.8164\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0664 - accuracy: 0.8179 - val_loss: 0.4073 - val_accuracy: 0.8159\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0661 - accuracy: 0.8182 - val_loss: 0.4015 - val_accuracy: 0.8214\n",
      "11년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2160 - accuracy: 0.8789 - val_loss: 0.5542 - val_accuracy: 0.7361\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1395 - accuracy: 0.7268 - val_loss: 1.0315 - val_accuracy: 0.3577\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 0.1380 - accuracy: 0.3554 - val_loss: 1.3371 - val_accuracy: 0.2234\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1547 - accuracy: 0.2318 - val_loss: 1.2999 - val_accuracy: 0.2359\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1498 - accuracy: 0.2421 - val_loss: 1.0667 - val_accuracy: 0.3437\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1314 - accuracy: 0.3485 - val_loss: 0.7909 - val_accuracy: 0.5340\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1145 - accuracy: 0.5377 - val_loss: 0.5740 - val_accuracy: 0.7232\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1083 - accuracy: 0.7030 - val_loss: 0.4481 - val_accuracy: 0.8139\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1113 - accuracy: 0.7926 - val_loss: 0.3931 - val_accuracy: 0.8429\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1148 - accuracy: 0.8242 - val_loss: 0.3814 - val_accuracy: 0.8460\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1127 - accuracy: 0.8279 - val_loss: 0.4010 - val_accuracy: 0.8320\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1057 - accuracy: 0.8126 - val_loss: 0.4506 - val_accuracy: 0.7947\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0979 - accuracy: 0.7771 - val_loss: 0.5271 - val_accuracy: 0.7351\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0932 - accuracy: 0.7292 - val_loss: 0.6151 - val_accuracy: 0.6801\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0927 - accuracy: 0.6763 - val_loss: 0.6888 - val_accuracy: 0.6413\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0942 - accuracy: 0.6416 - val_loss: 0.7245 - val_accuracy: 0.6267\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0949 - accuracy: 0.6280 - val_loss: 0.7138 - val_accuracy: 0.6340\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0935 - accuracy: 0.6378 - val_loss: 0.6645 - val_accuracy: 0.6625\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.0903 - accuracy: 0.6642 - val_loss: 0.5944 - val_accuracy: 0.7045\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0868 - accuracy: 0.6950 - val_loss: 0.5226 - val_accuracy: 0.7439\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0845 - accuracy: 0.7313 - val_loss: 0.4626 - val_accuracy: 0.7652\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0839 - accuracy: 0.7668 - val_loss: 0.4212 - val_accuracy: 0.7859\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0844 - accuracy: 0.7887 - val_loss: 0.3990 - val_accuracy: 0.8004\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0847 - accuracy: 0.8018 - val_loss: 0.3944 - val_accuracy: 0.8061\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0841 - accuracy: 0.8053 - val_loss: 0.4053 - val_accuracy: 0.7983\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0825 - accuracy: 0.7994 - val_loss: 0.4293 - val_accuracy: 0.7890\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0807 - accuracy: 0.7863 - val_loss: 0.4625 - val_accuracy: 0.7745\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0794 - accuracy: 0.7704 - val_loss: 0.4985 - val_accuracy: 0.7605\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0789 - accuracy: 0.7529 - val_loss: 0.5290 - val_accuracy: 0.7444\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0789 - accuracy: 0.7405 - val_loss: 0.5465 - val_accuracy: 0.7398\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0789 - accuracy: 0.7339 - val_loss: 0.5467 - val_accuracy: 0.7418\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0785 - accuracy: 0.7357 - val_loss: 0.5305 - val_accuracy: 0.7486\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0776 - accuracy: 0.7426 - val_loss: 0.5029 - val_accuracy: 0.7641\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0766 - accuracy: 0.7570 - val_loss: 0.4707 - val_accuracy: 0.7781\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0757 - accuracy: 0.7733 - val_loss: 0.4409 - val_accuracy: 0.7916\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0753 - accuracy: 0.7891 - val_loss: 0.4182 - val_accuracy: 0.8020\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0752 - accuracy: 0.8017 - val_loss: 0.4050 - val_accuracy: 0.8077\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0751 - accuracy: 0.8084 - val_loss: 0.4019 - val_accuracy: 0.8092\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0747 - accuracy: 0.8102 - val_loss: 0.4083 - val_accuracy: 0.8082\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0740 - accuracy: 0.8073 - val_loss: 0.4220 - val_accuracy: 0.8015\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0733 - accuracy: 0.8013 - val_loss: 0.4398 - val_accuracy: 0.7973\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0728 - accuracy: 0.7943 - val_loss: 0.4575 - val_accuracy: 0.7895\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0726 - accuracy: 0.7873 - val_loss: 0.4703 - val_accuracy: 0.7885\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0724 - accuracy: 0.7820 - val_loss: 0.4748 - val_accuracy: 0.7880\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0722 - accuracy: 0.7809 - val_loss: 0.4700 - val_accuracy: 0.7900\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0718 - accuracy: 0.7841 - val_loss: 0.4574 - val_accuracy: 0.7932\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0713 - accuracy: 0.7900 - val_loss: 0.4405 - val_accuracy: 0.7983\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0709 - accuracy: 0.7988 - val_loss: 0.4235 - val_accuracy: 0.8030\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0706 - accuracy: 0.8066 - val_loss: 0.4099 - val_accuracy: 0.8108\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0704 - accuracy: 0.8126 - val_loss: 0.4020 - val_accuracy: 0.8134\n",
      "12년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1555 - accuracy: 0.6173 - val_loss: 1.0099 - val_accuracy: 0.3071\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 0.1409 - accuracy: 0.2989 - val_loss: 0.8097 - val_accuracy: 0.4718\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1255 - accuracy: 0.4793 - val_loss: 0.6019 - val_accuracy: 0.6833\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.1203 - accuracy: 0.6878 - val_loss: 0.5366 - val_accuracy: 0.7248\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1190 - accuracy: 0.7282 - val_loss: 0.5578 - val_accuracy: 0.7121\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 312ms/step - loss: 0.1130 - accuracy: 0.7156 - val_loss: 0.6176 - val_accuracy: 0.6713\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1070 - accuracy: 0.6729 - val_loss: 0.6660 - val_accuracy: 0.6484\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1034 - accuracy: 0.6409 - val_loss: 0.6582 - val_accuracy: 0.6599\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0998 - accuracy: 0.6521 - val_loss: 0.5971 - val_accuracy: 0.7001\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0955 - accuracy: 0.6924 - val_loss: 0.5208 - val_accuracy: 0.7422\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0925 - accuracy: 0.7303 - val_loss: 0.4645 - val_accuracy: 0.7825\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0914 - accuracy: 0.7656 - val_loss: 0.4416 - val_accuracy: 0.7981\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0906 - accuracy: 0.7802 - val_loss: 0.4486 - val_accuracy: 0.7909\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0889 - accuracy: 0.7742 - val_loss: 0.4753 - val_accuracy: 0.7722\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0869 - accuracy: 0.7533 - val_loss: 0.5059 - val_accuracy: 0.7530\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0855 - accuracy: 0.7343 - val_loss: 0.5216 - val_accuracy: 0.7434\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0843 - accuracy: 0.7258 - val_loss: 0.5121 - val_accuracy: 0.7494\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0828 - accuracy: 0.7351 - val_loss: 0.4830 - val_accuracy: 0.7614\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0811 - accuracy: 0.7519 - val_loss: 0.4495 - val_accuracy: 0.7843\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0800 - accuracy: 0.7710 - val_loss: 0.4253 - val_accuracy: 0.7975\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0794 - accuracy: 0.7872 - val_loss: 0.4169 - val_accuracy: 0.7987\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0788 - accuracy: 0.7922 - val_loss: 0.4238 - val_accuracy: 0.7957\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0778 - accuracy: 0.7892 - val_loss: 0.4403 - val_accuracy: 0.7873\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0769 - accuracy: 0.7838 - val_loss: 0.4566 - val_accuracy: 0.7800\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0761 - accuracy: 0.7763 - val_loss: 0.4623 - val_accuracy: 0.7770\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0754 - accuracy: 0.7743 - val_loss: 0.4528 - val_accuracy: 0.7794\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0745 - accuracy: 0.7790 - val_loss: 0.4321 - val_accuracy: 0.7885\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0736 - accuracy: 0.7892 - val_loss: 0.4096 - val_accuracy: 0.8029\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0729 - accuracy: 0.7998 - val_loss: 0.3942 - val_accuracy: 0.8095\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0724 - accuracy: 0.8066 - val_loss: 0.3899 - val_accuracy: 0.8119\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0719 - accuracy: 0.8090 - val_loss: 0.3960 - val_accuracy: 0.8119\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0713 - accuracy: 0.8087 - val_loss: 0.4073 - val_accuracy: 0.8089\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0707 - accuracy: 0.8023 - val_loss: 0.4164 - val_accuracy: 0.8029\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0703 - accuracy: 0.7971 - val_loss: 0.4167 - val_accuracy: 0.8029\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0698 - accuracy: 0.7989 - val_loss: 0.4074 - val_accuracy: 0.8071\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0692 - accuracy: 0.8057 - val_loss: 0.3934 - val_accuracy: 0.8143\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0686 - accuracy: 0.8129 - val_loss: 0.3817 - val_accuracy: 0.8215\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0682 - accuracy: 0.8188 - val_loss: 0.3773 - val_accuracy: 0.8251\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0679 - accuracy: 0.8227 - val_loss: 0.3808 - val_accuracy: 0.8221\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0674 - accuracy: 0.8216 - val_loss: 0.3889 - val_accuracy: 0.8167\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0671 - accuracy: 0.8177 - val_loss: 0.3958 - val_accuracy: 0.8143\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0667 - accuracy: 0.8158 - val_loss: 0.3961 - val_accuracy: 0.8149\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0664 - accuracy: 0.8167 - val_loss: 0.3890 - val_accuracy: 0.8191\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0660 - accuracy: 0.8194 - val_loss: 0.3784 - val_accuracy: 0.8269\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0656 - accuracy: 0.8249 - val_loss: 0.3699 - val_accuracy: 0.8293\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0653 - accuracy: 0.8295 - val_loss: 0.3671 - val_accuracy: 0.8317\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0650 - accuracy: 0.8310 - val_loss: 0.3700 - val_accuracy: 0.8323\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0647 - accuracy: 0.8302 - val_loss: 0.3753 - val_accuracy: 0.8323\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0644 - accuracy: 0.8287 - val_loss: 0.3783 - val_accuracy: 0.8305\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0641 - accuracy: 0.8273 - val_loss: 0.3761 - val_accuracy: 0.8323\n",
      "13년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2475 - accuracy: 0.1149 - val_loss: 1.1799 - val_accuracy: 0.2443\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1596 - accuracy: 0.2737 - val_loss: 0.5638 - val_accuracy: 0.7229\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1609 - accuracy: 0.7096 - val_loss: 0.4283 - val_accuracy: 0.8419\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1747 - accuracy: 0.8327 - val_loss: 0.4301 - val_accuracy: 0.8298\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1603 - accuracy: 0.8272 - val_loss: 0.5143 - val_accuracy: 0.7521\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.1365 - accuracy: 0.7529 - val_loss: 0.6854 - val_accuracy: 0.6083\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1225 - accuracy: 0.6157 - val_loss: 0.8949 - val_accuracy: 0.4758\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1227 - accuracy: 0.4825 - val_loss: 1.0432 - val_accuracy: 0.4003\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1271 - accuracy: 0.4140 - val_loss: 1.0666 - val_accuracy: 0.3889\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1263 - accuracy: 0.4062 - val_loss: 0.9732 - val_accuracy: 0.4437\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1186 - accuracy: 0.4596 - val_loss: 0.8149 - val_accuracy: 0.5349\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1083 - accuracy: 0.5576 - val_loss: 0.6510 - val_accuracy: 0.6489\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1008 - accuracy: 0.6686 - val_loss: 0.5230 - val_accuracy: 0.7400\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0987 - accuracy: 0.7492 - val_loss: 0.4443 - val_accuracy: 0.7949\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1000 - accuracy: 0.8008 - val_loss: 0.4089 - val_accuracy: 0.8191\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1009 - accuracy: 0.8167 - val_loss: 0.4070 - val_accuracy: 0.8141\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0989 - accuracy: 0.8167 - val_loss: 0.4328 - val_accuracy: 0.7963\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0947 - accuracy: 0.7989 - val_loss: 0.4825 - val_accuracy: 0.7543\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0906 - accuracy: 0.7721 - val_loss: 0.5485 - val_accuracy: 0.7179\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0883 - accuracy: 0.7369 - val_loss: 0.6157 - val_accuracy: 0.6781\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0882 - accuracy: 0.7035 - val_loss: 0.6649 - val_accuracy: 0.6681\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0888 - accuracy: 0.6815 - val_loss: 0.6818 - val_accuracy: 0.6624\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0886 - accuracy: 0.6793 - val_loss: 0.6633 - val_accuracy: 0.6702\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0870 - accuracy: 0.6889 - val_loss: 0.6179 - val_accuracy: 0.6944\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0846 - accuracy: 0.7107 - val_loss: 0.5602 - val_accuracy: 0.7201\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0824 - accuracy: 0.7399 - val_loss: 0.5047 - val_accuracy: 0.7500\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0813 - accuracy: 0.7686 - val_loss: 0.4612 - val_accuracy: 0.7721\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0812 - accuracy: 0.7898 - val_loss: 0.4345 - val_accuracy: 0.7877\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0813 - accuracy: 0.8026 - val_loss: 0.4251 - val_accuracy: 0.7949\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0809 - accuracy: 0.8067 - val_loss: 0.4316 - val_accuracy: 0.7934\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0798 - accuracy: 0.8047 - val_loss: 0.4517 - val_accuracy: 0.7828\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0784 - accuracy: 0.7951 - val_loss: 0.4810 - val_accuracy: 0.7607\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0773 - accuracy: 0.7819 - val_loss: 0.5130 - val_accuracy: 0.7457\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0766 - accuracy: 0.7707 - val_loss: 0.5397 - val_accuracy: 0.7379\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0764 - accuracy: 0.7600 - val_loss: 0.5540 - val_accuracy: 0.7322\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0762 - accuracy: 0.7559 - val_loss: 0.5521 - val_accuracy: 0.7322\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0757 - accuracy: 0.7575 - val_loss: 0.5354 - val_accuracy: 0.7400\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0748 - accuracy: 0.7650 - val_loss: 0.5091 - val_accuracy: 0.7550\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0739 - accuracy: 0.7745 - val_loss: 0.4802 - val_accuracy: 0.7728\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0733 - accuracy: 0.7866 - val_loss: 0.4552 - val_accuracy: 0.7828\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0730 - accuracy: 0.7949 - val_loss: 0.4384 - val_accuracy: 0.7920\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0728 - accuracy: 0.8026 - val_loss: 0.4317 - val_accuracy: 0.8013\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0724 - accuracy: 0.8053 - val_loss: 0.4351 - val_accuracy: 0.7963\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0719 - accuracy: 0.8035 - val_loss: 0.4467 - val_accuracy: 0.7906\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0712 - accuracy: 0.8005 - val_loss: 0.4633 - val_accuracy: 0.7806\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0707 - accuracy: 0.7974 - val_loss: 0.4800 - val_accuracy: 0.7742\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0704 - accuracy: 0.7907 - val_loss: 0.4921 - val_accuracy: 0.7657\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0701 - accuracy: 0.7864 - val_loss: 0.4957 - val_accuracy: 0.7642\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0699 - accuracy: 0.7855 - val_loss: 0.4899 - val_accuracy: 0.7664\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0695 - accuracy: 0.7891 - val_loss: 0.4768 - val_accuracy: 0.7735\n",
      "14년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1846 - accuracy: 0.7480 - val_loss: 1.1587 - val_accuracy: 0.2402\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1603 - accuracy: 0.2391 - val_loss: 1.2693 - val_accuracy: 0.1697\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1572 - accuracy: 0.1832 - val_loss: 1.0108 - val_accuracy: 0.2977\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1383 - accuracy: 0.2994 - val_loss: 0.7111 - val_accuracy: 0.5727\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1248 - accuracy: 0.5742 - val_loss: 0.5314 - val_accuracy: 0.7607\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1224 - accuracy: 0.7576 - val_loss: 0.4724 - val_accuracy: 0.7972\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1195 - accuracy: 0.7994 - val_loss: 0.4884 - val_accuracy: 0.7815\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.1118 - accuracy: 0.7765 - val_loss: 0.5542 - val_accuracy: 0.7241\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1044 - accuracy: 0.7145 - val_loss: 0.6401 - val_accuracy: 0.6736\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1012 - accuracy: 0.6510 - val_loss: 0.6979 - val_accuracy: 0.6327\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1003 - accuracy: 0.6186 - val_loss: 0.6937 - val_accuracy: 0.6379\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0980 - accuracy: 0.6247 - val_loss: 0.6334 - val_accuracy: 0.6797\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 0.0939 - accuracy: 0.6638 - val_loss: 0.5491 - val_accuracy: 0.7258\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0899 - accuracy: 0.7171 - val_loss: 0.4732 - val_accuracy: 0.7728\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0880 - accuracy: 0.7674 - val_loss: 0.4238 - val_accuracy: 0.8007\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 0.0874 - accuracy: 0.7933 - val_loss: 0.4042 - val_accuracy: 0.8155\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0867 - accuracy: 0.8022 - val_loss: 0.4110 - val_accuracy: 0.8094\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0849 - accuracy: 0.7987 - val_loss: 0.4384 - val_accuracy: 0.7781\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0830 - accuracy: 0.7839 - val_loss: 0.4771 - val_accuracy: 0.7641\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0819 - accuracy: 0.7600 - val_loss: 0.5124 - val_accuracy: 0.7528\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0817 - accuracy: 0.7402 - val_loss: 0.5291 - val_accuracy: 0.7485\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0815 - accuracy: 0.7352 - val_loss: 0.5205 - val_accuracy: 0.7554\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0806 - accuracy: 0.7400 - val_loss: 0.4914 - val_accuracy: 0.7676\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0794 - accuracy: 0.7522 - val_loss: 0.4544 - val_accuracy: 0.7781\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0783 - accuracy: 0.7698 - val_loss: 0.4220 - val_accuracy: 0.7946\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0777 - accuracy: 0.7892 - val_loss: 0.4019 - val_accuracy: 0.8059\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0773 - accuracy: 0.8035 - val_loss: 0.3969 - val_accuracy: 0.8077\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0766 - accuracy: 0.8061 - val_loss: 0.4056 - val_accuracy: 0.8033\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0756 - accuracy: 0.8011 - val_loss: 0.4237 - val_accuracy: 0.7972\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0746 - accuracy: 0.7926 - val_loss: 0.4442 - val_accuracy: 0.7885\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0739 - accuracy: 0.7809 - val_loss: 0.4585 - val_accuracy: 0.7859\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0735 - accuracy: 0.7774 - val_loss: 0.4602 - val_accuracy: 0.7842\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0729 - accuracy: 0.7779 - val_loss: 0.4485 - val_accuracy: 0.7868\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0722 - accuracy: 0.7829 - val_loss: 0.4281 - val_accuracy: 0.7955\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0714 - accuracy: 0.7922 - val_loss: 0.4068 - val_accuracy: 0.8050\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0708 - accuracy: 0.8018 - val_loss: 0.3911 - val_accuracy: 0.8129\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0704 - accuracy: 0.8096 - val_loss: 0.3847 - val_accuracy: 0.8181\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0699 - accuracy: 0.8135 - val_loss: 0.3879 - val_accuracy: 0.8172\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0692 - accuracy: 0.8135 - val_loss: 0.3980 - val_accuracy: 0.8129\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0686 - accuracy: 0.8096 - val_loss: 0.4100 - val_accuracy: 0.8050\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0681 - accuracy: 0.8044 - val_loss: 0.4178 - val_accuracy: 0.8050\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0677 - accuracy: 0.8016 - val_loss: 0.4170 - val_accuracy: 0.8077\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0672 - accuracy: 0.8020 - val_loss: 0.4074 - val_accuracy: 0.8111\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0667 - accuracy: 0.8061 - val_loss: 0.3931 - val_accuracy: 0.8190\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0663 - accuracy: 0.8144 - val_loss: 0.3796 - val_accuracy: 0.8216\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0659 - accuracy: 0.8220 - val_loss: 0.3718 - val_accuracy: 0.8251\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0656 - accuracy: 0.8244 - val_loss: 0.3712 - val_accuracy: 0.8285\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0652 - accuracy: 0.8259 - val_loss: 0.3769 - val_accuracy: 0.8268\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0648 - accuracy: 0.8229 - val_loss: 0.3850 - val_accuracy: 0.8233\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0645 - accuracy: 0.8209 - val_loss: 0.3908 - val_accuracy: 0.8216\n",
      "15년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 342ms/step - loss: 0.1560 - accuracy: 0.7681 - val_loss: 1.0493 - val_accuracy: 0.3648\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1403 - accuracy: 0.3864 - val_loss: 1.0448 - val_accuracy: 0.3326\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1338 - accuracy: 0.3513 - val_loss: 0.7661 - val_accuracy: 0.5462\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1166 - accuracy: 0.5498 - val_loss: 0.5351 - val_accuracy: 0.7442\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1111 - accuracy: 0.7489 - val_loss: 0.4418 - val_accuracy: 0.8120\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1123 - accuracy: 0.8163 - val_loss: 0.4377 - val_accuracy: 0.8109\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.1078 - accuracy: 0.8138 - val_loss: 0.4881 - val_accuracy: 0.7686\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1005 - accuracy: 0.7753 - val_loss: 0.5718 - val_accuracy: 0.7119\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0964 - accuracy: 0.7169 - val_loss: 0.6474 - val_accuracy: 0.6774\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0959 - accuracy: 0.6771 - val_loss: 0.6707 - val_accuracy: 0.6574\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0949 - accuracy: 0.6645 - val_loss: 0.6343 - val_accuracy: 0.6852\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0919 - accuracy: 0.6868 - val_loss: 0.5646 - val_accuracy: 0.7253\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0886 - accuracy: 0.7319 - val_loss: 0.4947 - val_accuracy: 0.7753\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0867 - accuracy: 0.7692 - val_loss: 0.4452 - val_accuracy: 0.7931\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0865 - accuracy: 0.8018 - val_loss: 0.4225 - val_accuracy: 0.7953\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0861 - accuracy: 0.8099 - val_loss: 0.4247 - val_accuracy: 0.7931\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0846 - accuracy: 0.8087 - val_loss: 0.4476 - val_accuracy: 0.7775\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0825 - accuracy: 0.7934 - val_loss: 0.4835 - val_accuracy: 0.7675\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0811 - accuracy: 0.7731 - val_loss: 0.5189 - val_accuracy: 0.7430\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0807 - accuracy: 0.7531 - val_loss: 0.5384 - val_accuracy: 0.7353\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0804 - accuracy: 0.7408 - val_loss: 0.5330 - val_accuracy: 0.7375\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0796 - accuracy: 0.7439 - val_loss: 0.5060 - val_accuracy: 0.7442\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0783 - accuracy: 0.7570 - val_loss: 0.4694 - val_accuracy: 0.7653\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0771 - accuracy: 0.7806 - val_loss: 0.4365 - val_accuracy: 0.7864\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0764 - accuracy: 0.8009 - val_loss: 0.4160 - val_accuracy: 0.7931\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0759 - accuracy: 0.8096 - val_loss: 0.4109 - val_accuracy: 0.7964\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0751 - accuracy: 0.8143 - val_loss: 0.4201 - val_accuracy: 0.7887\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0739 - accuracy: 0.8112 - val_loss: 0.4392 - val_accuracy: 0.7764\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0728 - accuracy: 0.8012 - val_loss: 0.4606 - val_accuracy: 0.7709\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0721 - accuracy: 0.7909 - val_loss: 0.4748 - val_accuracy: 0.7642\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0716 - accuracy: 0.7865 - val_loss: 0.4752 - val_accuracy: 0.7653\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0710 - accuracy: 0.7879 - val_loss: 0.4616 - val_accuracy: 0.7697\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0701 - accuracy: 0.7937 - val_loss: 0.4401 - val_accuracy: 0.7831\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0693 - accuracy: 0.8029 - val_loss: 0.4191 - val_accuracy: 0.7976\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0687 - accuracy: 0.8151 - val_loss: 0.4055 - val_accuracy: 0.7987\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0683 - accuracy: 0.8232 - val_loss: 0.4024 - val_accuracy: 0.8020\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0677 - accuracy: 0.8263 - val_loss: 0.4092 - val_accuracy: 0.7964\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0670 - accuracy: 0.8238 - val_loss: 0.4221 - val_accuracy: 0.7909\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0663 - accuracy: 0.8185 - val_loss: 0.4346 - val_accuracy: 0.7842\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0659 - accuracy: 0.8143 - val_loss: 0.4402 - val_accuracy: 0.7831\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0654 - accuracy: 0.8121 - val_loss: 0.4356 - val_accuracy: 0.7853\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0649 - accuracy: 0.8165 - val_loss: 0.4231 - val_accuracy: 0.7942\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0643 - accuracy: 0.8257 - val_loss: 0.4087 - val_accuracy: 0.8065\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0639 - accuracy: 0.8346 - val_loss: 0.3985 - val_accuracy: 0.8120\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0635 - accuracy: 0.8413 - val_loss: 0.3961 - val_accuracy: 0.8120\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0631 - accuracy: 0.8419 - val_loss: 0.4014 - val_accuracy: 0.8098\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0626 - accuracy: 0.8405 - val_loss: 0.4108 - val_accuracy: 0.8087\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0622 - accuracy: 0.8391 - val_loss: 0.4190 - val_accuracy: 0.8076\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0618 - accuracy: 0.8366 - val_loss: 0.4211 - val_accuracy: 0.8065\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0614 - accuracy: 0.8366 - val_loss: 0.4158 - val_accuracy: 0.8120\n",
      "16년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 300ms/step - loss: 0.1452 - accuracy: 0.8016 - val_loss: 1.1437 - val_accuracy: 0.2141\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1432 - accuracy: 0.2022 - val_loss: 0.9092 - val_accuracy: 0.3578\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1232 - accuracy: 0.3723 - val_loss: 0.5828 - val_accuracy: 0.7125\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1078 - accuracy: 0.6915 - val_loss: 0.4221 - val_accuracy: 0.8425\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 0.1085 - accuracy: 0.8188 - val_loss: 0.3913 - val_accuracy: 0.8532\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1060 - accuracy: 0.8326 - val_loss: 0.4292 - val_accuracy: 0.8211\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0978 - accuracy: 0.8085 - val_loss: 0.5139 - val_accuracy: 0.7661\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0917 - accuracy: 0.7542 - val_loss: 0.6067 - val_accuracy: 0.6942\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0904 - accuracy: 0.6923 - val_loss: 0.6502 - val_accuracy: 0.6682\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0898 - accuracy: 0.6713 - val_loss: 0.6216 - val_accuracy: 0.6865\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0866 - accuracy: 0.6934 - val_loss: 0.5477 - val_accuracy: 0.7431\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0823 - accuracy: 0.7408 - val_loss: 0.4707 - val_accuracy: 0.7982\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0798 - accuracy: 0.7959 - val_loss: 0.4175 - val_accuracy: 0.8242\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0793 - accuracy: 0.8383 - val_loss: 0.3948 - val_accuracy: 0.8379\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0787 - accuracy: 0.8547 - val_loss: 0.3987 - val_accuracy: 0.8349\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0768 - accuracy: 0.8509 - val_loss: 0.4240 - val_accuracy: 0.8104\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0741 - accuracy: 0.8379 - val_loss: 0.4626 - val_accuracy: 0.7920\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0724 - accuracy: 0.8066 - val_loss: 0.4992 - val_accuracy: 0.7691\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0719 - accuracy: 0.7810 - val_loss: 0.5157 - val_accuracy: 0.7569\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0715 - accuracy: 0.7722 - val_loss: 0.5037 - val_accuracy: 0.7630\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0704 - accuracy: 0.7813 - val_loss: 0.4700 - val_accuracy: 0.7966\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0688 - accuracy: 0.8012 - val_loss: 0.4304 - val_accuracy: 0.8150\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0676 - accuracy: 0.8295 - val_loss: 0.3988 - val_accuracy: 0.8226\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0671 - accuracy: 0.8479 - val_loss: 0.3825 - val_accuracy: 0.8242\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0666 - accuracy: 0.8532 - val_loss: 0.3823 - val_accuracy: 0.8303\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0656 - accuracy: 0.8559 - val_loss: 0.3958 - val_accuracy: 0.8211\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0643 - accuracy: 0.8517 - val_loss: 0.4174 - val_accuracy: 0.8165\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0632 - accuracy: 0.8402 - val_loss: 0.4382 - val_accuracy: 0.8073\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0626 - accuracy: 0.8284 - val_loss: 0.4483 - val_accuracy: 0.8028\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0620 - accuracy: 0.8234 - val_loss: 0.4427 - val_accuracy: 0.7997\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0612 - accuracy: 0.8261 - val_loss: 0.4244 - val_accuracy: 0.8165\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0602 - accuracy: 0.8394 - val_loss: 0.4018 - val_accuracy: 0.8303\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0595 - accuracy: 0.8509 - val_loss: 0.3833 - val_accuracy: 0.8425\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0590 - accuracy: 0.8582 - val_loss: 0.3741 - val_accuracy: 0.8440\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0585 - accuracy: 0.8635 - val_loss: 0.3752 - val_accuracy: 0.8440\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0579 - accuracy: 0.8647 - val_loss: 0.3846 - val_accuracy: 0.8349\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0571 - accuracy: 0.8586 - val_loss: 0.3971 - val_accuracy: 0.8318\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0566 - accuracy: 0.8528 - val_loss: 0.4059 - val_accuracy: 0.8242\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0561 - accuracy: 0.8521 - val_loss: 0.4058 - val_accuracy: 0.8196\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0557 - accuracy: 0.8517 - val_loss: 0.3962 - val_accuracy: 0.8272\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0551 - accuracy: 0.8570 - val_loss: 0.3813 - val_accuracy: 0.8349\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0545 - accuracy: 0.8624 - val_loss: 0.3677 - val_accuracy: 0.8440\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0541 - accuracy: 0.8677 - val_loss: 0.3601 - val_accuracy: 0.8517\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0537 - accuracy: 0.8723 - val_loss: 0.3604 - val_accuracy: 0.8532\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0532 - accuracy: 0.8723 - val_loss: 0.3671 - val_accuracy: 0.8394\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0527 - accuracy: 0.8704 - val_loss: 0.3764 - val_accuracy: 0.8379\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0523 - accuracy: 0.8685 - val_loss: 0.3831 - val_accuracy: 0.8303\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0519 - accuracy: 0.8658 - val_loss: 0.3832 - val_accuracy: 0.8333\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0515 - accuracy: 0.8662 - val_loss: 0.3768 - val_accuracy: 0.8410\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0511 - accuracy: 0.8696 - val_loss: 0.3674 - val_accuracy: 0.8471\n",
      "17년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 0.1789 - accuracy: 0.2057 - val_loss: 0.6676 - val_accuracy: 0.6177\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1512 - accuracy: 0.6538 - val_loss: 0.4858 - val_accuracy: 0.7879\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1457 - accuracy: 0.7885 - val_loss: 0.5256 - val_accuracy: 0.7599\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1270 - accuracy: 0.7483 - val_loss: 0.6735 - val_accuracy: 0.6154\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1167 - accuracy: 0.6224 - val_loss: 0.8142 - val_accuracy: 0.5385\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1170 - accuracy: 0.5198 - val_loss: 0.8301 - val_accuracy: 0.5478\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1149 - accuracy: 0.5181 - val_loss: 0.7311 - val_accuracy: 0.5991\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1073 - accuracy: 0.5781 - val_loss: 0.5924 - val_accuracy: 0.6876\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0995 - accuracy: 0.6772 - val_loss: 0.4781 - val_accuracy: 0.7925\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0955 - accuracy: 0.7791 - val_loss: 0.4144 - val_accuracy: 0.8275\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0936 - accuracy: 0.8205 - val_loss: 0.3986 - val_accuracy: 0.8298\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0907 - accuracy: 0.8386 - val_loss: 0.4215 - val_accuracy: 0.8205\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0866 - accuracy: 0.8234 - val_loss: 0.4734 - val_accuracy: 0.7879\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0834 - accuracy: 0.7896 - val_loss: 0.5347 - val_accuracy: 0.7459\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0826 - accuracy: 0.7529 - val_loss: 0.5762 - val_accuracy: 0.7296\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0827 - accuracy: 0.7261 - val_loss: 0.5767 - val_accuracy: 0.7249\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0818 - accuracy: 0.7296 - val_loss: 0.5393 - val_accuracy: 0.7436\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0796 - accuracy: 0.7517 - val_loss: 0.4843 - val_accuracy: 0.7716\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0774 - accuracy: 0.7844 - val_loss: 0.4334 - val_accuracy: 0.7902\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0761 - accuracy: 0.8071 - val_loss: 0.3998 - val_accuracy: 0.8135\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0753 - accuracy: 0.8234 - val_loss: 0.3872 - val_accuracy: 0.8228\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0743 - accuracy: 0.8304 - val_loss: 0.3938 - val_accuracy: 0.8159\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0729 - accuracy: 0.8275 - val_loss: 0.4149 - val_accuracy: 0.8042\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0714 - accuracy: 0.8176 - val_loss: 0.4424 - val_accuracy: 0.7902\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0705 - accuracy: 0.8024 - val_loss: 0.4652 - val_accuracy: 0.7692\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0702 - accuracy: 0.7861 - val_loss: 0.4734 - val_accuracy: 0.7622\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0697 - accuracy: 0.7826 - val_loss: 0.4635 - val_accuracy: 0.7716\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0688 - accuracy: 0.7896 - val_loss: 0.4401 - val_accuracy: 0.7809\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0676 - accuracy: 0.8030 - val_loss: 0.4125 - val_accuracy: 0.8019\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0666 - accuracy: 0.8176 - val_loss: 0.3897 - val_accuracy: 0.8182\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0659 - accuracy: 0.8304 - val_loss: 0.3769 - val_accuracy: 0.8228\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0652 - accuracy: 0.8351 - val_loss: 0.3759 - val_accuracy: 0.8275\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0643 - accuracy: 0.8351 - val_loss: 0.3851 - val_accuracy: 0.8252\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0634 - accuracy: 0.8333 - val_loss: 0.4000 - val_accuracy: 0.8205\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0626 - accuracy: 0.8293 - val_loss: 0.4141 - val_accuracy: 0.8112\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0620 - accuracy: 0.8211 - val_loss: 0.4208 - val_accuracy: 0.8065\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0614 - accuracy: 0.8182 - val_loss: 0.4165 - val_accuracy: 0.8112\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0608 - accuracy: 0.8205 - val_loss: 0.4032 - val_accuracy: 0.8205\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0600 - accuracy: 0.8269 - val_loss: 0.3863 - val_accuracy: 0.8275\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0593 - accuracy: 0.8368 - val_loss: 0.3720 - val_accuracy: 0.8438\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0587 - accuracy: 0.8450 - val_loss: 0.3645 - val_accuracy: 0.8462\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0581 - accuracy: 0.8473 - val_loss: 0.3650 - val_accuracy: 0.8438\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0574 - accuracy: 0.8508 - val_loss: 0.3718 - val_accuracy: 0.8345\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0568 - accuracy: 0.8467 - val_loss: 0.3810 - val_accuracy: 0.8298\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0562 - accuracy: 0.8421 - val_loss: 0.3875 - val_accuracy: 0.8228\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0558 - accuracy: 0.8403 - val_loss: 0.3877 - val_accuracy: 0.8228\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0553 - accuracy: 0.8432 - val_loss: 0.3810 - val_accuracy: 0.8275\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0547 - accuracy: 0.8462 - val_loss: 0.3705 - val_accuracy: 0.8345\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0541 - accuracy: 0.8520 - val_loss: 0.3603 - val_accuracy: 0.8438\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0536 - accuracy: 0.8578 - val_loss: 0.3543 - val_accuracy: 0.8485\n",
      "18년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 508ms/step - loss: 0.1849 - accuracy: 0.7190 - val_loss: 1.0503 - val_accuracy: 0.4762\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1497 - accuracy: 0.4560 - val_loss: 1.2089 - val_accuracy: 0.3571\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1447 - accuracy: 0.3607 - val_loss: 0.9942 - val_accuracy: 0.4143\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.1251 - accuracy: 0.4250 - val_loss: 0.6891 - val_accuracy: 0.5857\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1073 - accuracy: 0.6369 - val_loss: 0.4860 - val_accuracy: 0.8048\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1036 - accuracy: 0.8024 - val_loss: 0.4127 - val_accuracy: 0.8571\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1037 - accuracy: 0.8417 - val_loss: 0.4165 - val_accuracy: 0.8429\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0980 - accuracy: 0.8405 - val_loss: 0.4693 - val_accuracy: 0.7905\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0901 - accuracy: 0.8202 - val_loss: 0.5529 - val_accuracy: 0.7238\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0857 - accuracy: 0.7679 - val_loss: 0.6315 - val_accuracy: 0.7048\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0848 - accuracy: 0.7321 - val_loss: 0.6644 - val_accuracy: 0.6810\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0838 - accuracy: 0.7119 - val_loss: 0.6397 - val_accuracy: 0.6952\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0807 - accuracy: 0.7345 - val_loss: 0.5771 - val_accuracy: 0.7333\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0766 - accuracy: 0.7726 - val_loss: 0.5068 - val_accuracy: 0.7667\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0735 - accuracy: 0.8036 - val_loss: 0.4511 - val_accuracy: 0.7857\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0721 - accuracy: 0.8369 - val_loss: 0.4186 - val_accuracy: 0.8143\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0715 - accuracy: 0.8536 - val_loss: 0.4089 - val_accuracy: 0.8143\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0702 - accuracy: 0.8631 - val_loss: 0.4187 - val_accuracy: 0.8143\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0679 - accuracy: 0.8524 - val_loss: 0.4438 - val_accuracy: 0.7905\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0656 - accuracy: 0.8429 - val_loss: 0.4770 - val_accuracy: 0.7810\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0641 - accuracy: 0.8381 - val_loss: 0.5069 - val_accuracy: 0.7571\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0634 - accuracy: 0.8179 - val_loss: 0.5215 - val_accuracy: 0.7524\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0627 - accuracy: 0.8119 - val_loss: 0.5150 - val_accuracy: 0.7571\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0615 - accuracy: 0.8155 - val_loss: 0.4909 - val_accuracy: 0.7619\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0599 - accuracy: 0.8298 - val_loss: 0.4590 - val_accuracy: 0.7762\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0584 - accuracy: 0.8381 - val_loss: 0.4295 - val_accuracy: 0.7952\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0574 - accuracy: 0.8500 - val_loss: 0.4097 - val_accuracy: 0.8190\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0567 - accuracy: 0.8607 - val_loss: 0.4022 - val_accuracy: 0.8333\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0557 - accuracy: 0.8655 - val_loss: 0.4064 - val_accuracy: 0.8333\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0544 - accuracy: 0.8655 - val_loss: 0.4193 - val_accuracy: 0.8143\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0530 - accuracy: 0.8571 - val_loss: 0.4361 - val_accuracy: 0.8048\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0519 - accuracy: 0.8536 - val_loss: 0.4503 - val_accuracy: 0.7905\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0511 - accuracy: 0.8524 - val_loss: 0.4561 - val_accuracy: 0.8000\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0503 - accuracy: 0.8548 - val_loss: 0.4511 - val_accuracy: 0.8048\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0494 - accuracy: 0.8595 - val_loss: 0.4374 - val_accuracy: 0.8048\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0484 - accuracy: 0.8690 - val_loss: 0.4200 - val_accuracy: 0.8190\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0475 - accuracy: 0.8821 - val_loss: 0.4047 - val_accuracy: 0.8286\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0468 - accuracy: 0.8869 - val_loss: 0.3951 - val_accuracy: 0.8333\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0461 - accuracy: 0.8940 - val_loss: 0.3927 - val_accuracy: 0.8333\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0454 - accuracy: 0.8940 - val_loss: 0.3970 - val_accuracy: 0.8286\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0446 - accuracy: 0.8929 - val_loss: 0.4056 - val_accuracy: 0.8238\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0438 - accuracy: 0.8940 - val_loss: 0.4147 - val_accuracy: 0.8286\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0432 - accuracy: 0.8917 - val_loss: 0.4201 - val_accuracy: 0.8286\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0426 - accuracy: 0.8917 - val_loss: 0.4192 - val_accuracy: 0.8286\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0420 - accuracy: 0.8905 - val_loss: 0.4122 - val_accuracy: 0.8286\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0413 - accuracy: 0.8917 - val_loss: 0.4019 - val_accuracy: 0.8333\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0406 - accuracy: 0.8952 - val_loss: 0.3918 - val_accuracy: 0.8476\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0401 - accuracy: 0.9048 - val_loss: 0.3851 - val_accuracy: 0.8476\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0395 - accuracy: 0.9083 - val_loss: 0.3832 - val_accuracy: 0.8476\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0390 - accuracy: 0.9107 - val_loss: 0.3857 - val_accuracy: 0.8476\n",
      "1년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1453 - accuracy: 0.5398 - val_loss: 0.8921 - val_accuracy: 0.3841\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1293 - accuracy: 0.3936 - val_loss: 0.7697 - val_accuracy: 0.4721\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1163 - accuracy: 0.4788 - val_loss: 0.6043 - val_accuracy: 0.6659\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.1065 - accuracy: 0.6682 - val_loss: 0.5025 - val_accuracy: 0.7689\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1008 - accuracy: 0.7709 - val_loss: 0.4697 - val_accuracy: 0.7868\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0954 - accuracy: 0.7895 - val_loss: 0.4791 - val_accuracy: 0.7904\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0900 - accuracy: 0.7908 - val_loss: 0.5072 - val_accuracy: 0.7959\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0862 - accuracy: 0.7949 - val_loss: 0.5310 - val_accuracy: 0.8048\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0842 - accuracy: 0.8034 - val_loss: 0.5347 - val_accuracy: 0.8081\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0828 - accuracy: 0.8076 - val_loss: 0.5179 - val_accuracy: 0.8117\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0815 - accuracy: 0.8110 - val_loss: 0.4912 - val_accuracy: 0.8174\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0805 - accuracy: 0.8191 - val_loss: 0.4659 - val_accuracy: 0.8200\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0798 - accuracy: 0.8228 - val_loss: 0.4493 - val_accuracy: 0.8200\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0793 - accuracy: 0.8229 - val_loss: 0.4434 - val_accuracy: 0.8200\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0786 - accuracy: 0.8228 - val_loss: 0.4474 - val_accuracy: 0.8176\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0778 - accuracy: 0.8195 - val_loss: 0.4578 - val_accuracy: 0.8166\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0770 - accuracy: 0.8181 - val_loss: 0.4699 - val_accuracy: 0.8125\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0765 - accuracy: 0.8120 - val_loss: 0.4782 - val_accuracy: 0.8107\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0762 - accuracy: 0.8104 - val_loss: 0.4786 - val_accuracy: 0.8073\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0759 - accuracy: 0.8042 - val_loss: 0.4704 - val_accuracy: 0.7989\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0756 - accuracy: 0.7986 - val_loss: 0.4562 - val_accuracy: 0.7961\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0753 - accuracy: 0.7967 - val_loss: 0.4407 - val_accuracy: 0.8018\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0751 - accuracy: 0.8008 - val_loss: 0.4287 - val_accuracy: 0.8038\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0750 - accuracy: 0.8026 - val_loss: 0.4232 - val_accuracy: 0.8036\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0748 - accuracy: 0.8026 - val_loss: 0.4249 - val_accuracy: 0.7967\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0746 - accuracy: 0.7970 - val_loss: 0.4322 - val_accuracy: 0.7843\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0744 - accuracy: 0.7863 - val_loss: 0.4415 - val_accuracy: 0.7783\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0743 - accuracy: 0.7789 - val_loss: 0.4485 - val_accuracy: 0.7726\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0742 - accuracy: 0.7727 - val_loss: 0.4498 - val_accuracy: 0.7744\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0741 - accuracy: 0.7742 - val_loss: 0.4449 - val_accuracy: 0.7815\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0740 - accuracy: 0.7840 - val_loss: 0.4361 - val_accuracy: 0.7989\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0739 - accuracy: 0.7993 - val_loss: 0.4272 - val_accuracy: 0.8101\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0739 - accuracy: 0.8082 - val_loss: 0.4220 - val_accuracy: 0.8129\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0738 - accuracy: 0.8126 - val_loss: 0.4219 - val_accuracy: 0.8133\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0738 - accuracy: 0.8130 - val_loss: 0.4265 - val_accuracy: 0.8121\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0737 - accuracy: 0.8112 - val_loss: 0.4333 - val_accuracy: 0.8099\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0736 - accuracy: 0.8075 - val_loss: 0.4388 - val_accuracy: 0.8016\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0736 - accuracy: 0.8016 - val_loss: 0.4405 - val_accuracy: 0.7994\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0735 - accuracy: 0.7989 - val_loss: 0.4378 - val_accuracy: 0.8032\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0735 - accuracy: 0.8030 - val_loss: 0.4323 - val_accuracy: 0.8105\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0734 - accuracy: 0.8092 - val_loss: 0.4269 - val_accuracy: 0.8131\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0733 - accuracy: 0.8126 - val_loss: 0.4241 - val_accuracy: 0.8146\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0732 - accuracy: 0.8141 - val_loss: 0.4250 - val_accuracy: 0.8146\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0731 - accuracy: 0.8138 - val_loss: 0.4291 - val_accuracy: 0.8129\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0730 - accuracy: 0.8124 - val_loss: 0.4342 - val_accuracy: 0.8109\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0730 - accuracy: 0.8091 - val_loss: 0.4377 - val_accuracy: 0.8081\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0729 - accuracy: 0.8063 - val_loss: 0.4381 - val_accuracy: 0.8062\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0729 - accuracy: 0.8052 - val_loss: 0.4353 - val_accuracy: 0.8083\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0728 - accuracy: 0.8071 - val_loss: 0.4310 - val_accuracy: 0.8113\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0728 - accuracy: 0.8100 - val_loss: 0.4273 - val_accuracy: 0.8125\n",
      "2년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2076 - accuracy: 0.8565 - val_loss: 0.6423 - val_accuracy: 0.6348\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1529 - accuracy: 0.6388 - val_loss: 1.0148 - val_accuracy: 0.2913\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1458 - accuracy: 0.2933 - val_loss: 1.2504 - val_accuracy: 0.1947\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.1533 - accuracy: 0.1930 - val_loss: 1.2442 - val_accuracy: 0.1962\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1496 - accuracy: 0.1955 - val_loss: 1.0824 - val_accuracy: 0.2613\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1365 - accuracy: 0.2612 - val_loss: 0.8647 - val_accuracy: 0.4127\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.1224 - accuracy: 0.4142 - val_loss: 0.6662 - val_accuracy: 0.5976\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.1135 - accuracy: 0.6019 - val_loss: 0.5261 - val_accuracy: 0.7490\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1113 - accuracy: 0.7479 - val_loss: 0.4470 - val_accuracy: 0.8086\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1120 - accuracy: 0.8052 - val_loss: 0.4131 - val_accuracy: 0.8253\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1110 - accuracy: 0.8206 - val_loss: 0.4101 - val_accuracy: 0.8234\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1068 - accuracy: 0.8189 - val_loss: 0.4312 - val_accuracy: 0.8075\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.1008 - accuracy: 0.8020 - val_loss: 0.4725 - val_accuracy: 0.7790\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0956 - accuracy: 0.7753 - val_loss: 0.5274 - val_accuracy: 0.7601\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 0.0924 - accuracy: 0.7565 - val_loss: 0.5837 - val_accuracy: 0.7427\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0915 - accuracy: 0.7403 - val_loss: 0.6267 - val_accuracy: 0.7290\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0916 - accuracy: 0.7234 - val_loss: 0.6450 - val_accuracy: 0.7209\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0913 - accuracy: 0.7139 - val_loss: 0.6352 - val_accuracy: 0.7292\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0899 - accuracy: 0.7231 - val_loss: 0.6023 - val_accuracy: 0.7418\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0878 - accuracy: 0.7392 - val_loss: 0.5561 - val_accuracy: 0.7564\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0854 - accuracy: 0.7528 - val_loss: 0.5071 - val_accuracy: 0.7722\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0836 - accuracy: 0.7680 - val_loss: 0.4632 - val_accuracy: 0.7929\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0827 - accuracy: 0.7871 - val_loss: 0.4294 - val_accuracy: 0.8062\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0824 - accuracy: 0.8014 - val_loss: 0.4072 - val_accuracy: 0.8160\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0823 - accuracy: 0.8133 - val_loss: 0.3965 - val_accuracy: 0.8214\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0820 - accuracy: 0.8179 - val_loss: 0.3963 - val_accuracy: 0.8201\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0813 - accuracy: 0.8170 - val_loss: 0.4051 - val_accuracy: 0.8171\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0802 - accuracy: 0.8141 - val_loss: 0.4212 - val_accuracy: 0.8107\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0791 - accuracy: 0.8079 - val_loss: 0.4419 - val_accuracy: 0.7999\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0783 - accuracy: 0.7970 - val_loss: 0.4636 - val_accuracy: 0.7914\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0779 - accuracy: 0.7899 - val_loss: 0.4821 - val_accuracy: 0.7873\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0777 - accuracy: 0.7839 - val_loss: 0.4939 - val_accuracy: 0.7820\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0776 - accuracy: 0.7797 - val_loss: 0.4967 - val_accuracy: 0.7809\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0773 - accuracy: 0.7782 - val_loss: 0.4901 - val_accuracy: 0.7818\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0769 - accuracy: 0.7813 - val_loss: 0.4759 - val_accuracy: 0.7883\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0763 - accuracy: 0.7867 - val_loss: 0.4574 - val_accuracy: 0.7933\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0758 - accuracy: 0.7937 - val_loss: 0.4380 - val_accuracy: 0.8010\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0754 - accuracy: 0.8020 - val_loss: 0.4209 - val_accuracy: 0.8090\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0752 - accuracy: 0.8086 - val_loss: 0.4082 - val_accuracy: 0.8153\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0751 - accuracy: 0.8143 - val_loss: 0.4011 - val_accuracy: 0.8184\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0750 - accuracy: 0.8168 - val_loss: 0.4000 - val_accuracy: 0.8179\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0748 - accuracy: 0.8168 - val_loss: 0.4044 - val_accuracy: 0.8160\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0745 - accuracy: 0.8148 - val_loss: 0.4130 - val_accuracy: 0.8112\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0742 - accuracy: 0.8113 - val_loss: 0.4241 - val_accuracy: 0.8047\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0740 - accuracy: 0.8053 - val_loss: 0.4354 - val_accuracy: 0.7979\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0738 - accuracy: 0.7989 - val_loss: 0.4445 - val_accuracy: 0.7907\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0737 - accuracy: 0.7932 - val_loss: 0.4496 - val_accuracy: 0.7894\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0737 - accuracy: 0.7897 - val_loss: 0.4496 - val_accuracy: 0.7892\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0736 - accuracy: 0.7890 - val_loss: 0.4448 - val_accuracy: 0.7910\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0734 - accuracy: 0.7924 - val_loss: 0.4366 - val_accuracy: 0.7966\n",
      "3년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 0.3062 - accuracy: 0.8841 - val_loss: 0.3763 - val_accuracy: 0.8727\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2007 - accuracy: 0.8747 - val_loss: 0.5685 - val_accuracy: 0.7259\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1400 - accuracy: 0.7248 - val_loss: 0.9745 - val_accuracy: 0.2935\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1361 - accuracy: 0.2929 - val_loss: 1.3360 - val_accuracy: 0.1625\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1550 - accuracy: 0.1581 - val_loss: 1.4744 - val_accuracy: 0.1404\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1633 - accuracy: 0.1413 - val_loss: 1.4070 - val_accuracy: 0.1519\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1559 - accuracy: 0.1507 - val_loss: 1.2092 - val_accuracy: 0.2013\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1387 - accuracy: 0.2015 - val_loss: 0.9599 - val_accuracy: 0.3652\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1195 - accuracy: 0.3661 - val_loss: 0.7268 - val_accuracy: 0.6084\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1058 - accuracy: 0.6080 - val_loss: 0.5512 - val_accuracy: 0.7481\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1009 - accuracy: 0.7495 - val_loss: 0.4408 - val_accuracy: 0.8036\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1032 - accuracy: 0.8080 - val_loss: 0.3811 - val_accuracy: 0.8352\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1078 - accuracy: 0.8369 - val_loss: 0.3538 - val_accuracy: 0.8474\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1101 - accuracy: 0.8509 - val_loss: 0.3474 - val_accuracy: 0.8530\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1084 - accuracy: 0.8539 - val_loss: 0.3577 - val_accuracy: 0.8469\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1031 - accuracy: 0.8494 - val_loss: 0.3846 - val_accuracy: 0.8345\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0964 - accuracy: 0.8356 - val_loss: 0.4287 - val_accuracy: 0.8029\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0907 - accuracy: 0.8106 - val_loss: 0.4876 - val_accuracy: 0.7774\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0873 - accuracy: 0.7866 - val_loss: 0.5538 - val_accuracy: 0.7460\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0866 - accuracy: 0.7547 - val_loss: 0.6160 - val_accuracy: 0.7151\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0876 - accuracy: 0.7233 - val_loss: 0.6620 - val_accuracy: 0.6952\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0889 - accuracy: 0.6994 - val_loss: 0.6831 - val_accuracy: 0.6852\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0894 - accuracy: 0.6899 - val_loss: 0.6770 - val_accuracy: 0.6910\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0885 - accuracy: 0.6960 - val_loss: 0.6472 - val_accuracy: 0.7081\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0866 - accuracy: 0.7134 - val_loss: 0.6015 - val_accuracy: 0.7303\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0840 - accuracy: 0.7390 - val_loss: 0.5491 - val_accuracy: 0.7519\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0818 - accuracy: 0.7619 - val_loss: 0.4980 - val_accuracy: 0.7706\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0802 - accuracy: 0.7833 - val_loss: 0.4538 - val_accuracy: 0.7921\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0797 - accuracy: 0.8020 - val_loss: 0.4197 - val_accuracy: 0.8127\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0798 - accuracy: 0.8209 - val_loss: 0.3963 - val_accuracy: 0.8233\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0802 - accuracy: 0.8294 - val_loss: 0.3835 - val_accuracy: 0.8268\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0804 - accuracy: 0.8333 - val_loss: 0.3801 - val_accuracy: 0.8291\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0801 - accuracy: 0.8343 - val_loss: 0.3853 - val_accuracy: 0.8258\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0794 - accuracy: 0.8318 - val_loss: 0.3981 - val_accuracy: 0.8202\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0784 - accuracy: 0.8260 - val_loss: 0.4168 - val_accuracy: 0.8134\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0774 - accuracy: 0.8193 - val_loss: 0.4396 - val_accuracy: 0.8057\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0767 - accuracy: 0.8103 - val_loss: 0.4635 - val_accuracy: 0.7966\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0764 - accuracy: 0.8013 - val_loss: 0.4854 - val_accuracy: 0.7851\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0763 - accuracy: 0.7941 - val_loss: 0.5020 - val_accuracy: 0.7814\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0764 - accuracy: 0.7892 - val_loss: 0.5109 - val_accuracy: 0.7781\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0764 - accuracy: 0.7860 - val_loss: 0.5111 - val_accuracy: 0.7772\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0761 - accuracy: 0.7854 - val_loss: 0.5031 - val_accuracy: 0.7814\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0757 - accuracy: 0.7893 - val_loss: 0.4887 - val_accuracy: 0.7865\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0752 - accuracy: 0.7948 - val_loss: 0.4706 - val_accuracy: 0.7947\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0747 - accuracy: 0.8014 - val_loss: 0.4514 - val_accuracy: 0.8069\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0743 - accuracy: 0.8086 - val_loss: 0.4336 - val_accuracy: 0.8118\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0741 - accuracy: 0.8145 - val_loss: 0.4192 - val_accuracy: 0.8172\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0740 - accuracy: 0.8193 - val_loss: 0.4093 - val_accuracy: 0.8184\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0740 - accuracy: 0.8233 - val_loss: 0.4043 - val_accuracy: 0.8205\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0738 - accuracy: 0.8253 - val_loss: 0.4042 - val_accuracy: 0.8207\n",
      "4년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1413 - accuracy: 0.2655 - val_loss: 0.5525 - val_accuracy: 0.7448\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.1320 - accuracy: 0.7514 - val_loss: 0.5038 - val_accuracy: 0.7878\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.1262 - accuracy: 0.7918 - val_loss: 0.5770 - val_accuracy: 0.7253\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1138 - accuracy: 0.7273 - val_loss: 0.6948 - val_accuracy: 0.6095\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1084 - accuracy: 0.6128 - val_loss: 0.7559 - val_accuracy: 0.5640\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1065 - accuracy: 0.5639 - val_loss: 0.7138 - val_accuracy: 0.6181\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1018 - accuracy: 0.6173 - val_loss: 0.6126 - val_accuracy: 0.7071\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0959 - accuracy: 0.7064 - val_loss: 0.5119 - val_accuracy: 0.7650\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 0.0923 - accuracy: 0.7697 - val_loss: 0.4460 - val_accuracy: 0.7977\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0911 - accuracy: 0.8036 - val_loss: 0.4205 - val_accuracy: 0.8118\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0897 - accuracy: 0.8156 - val_loss: 0.4276 - val_accuracy: 0.8050\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0872 - accuracy: 0.8093 - val_loss: 0.4578 - val_accuracy: 0.7871\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0847 - accuracy: 0.7914 - val_loss: 0.4986 - val_accuracy: 0.7693\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0832 - accuracy: 0.7722 - val_loss: 0.5331 - val_accuracy: 0.7562\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0827 - accuracy: 0.7575 - val_loss: 0.5464 - val_accuracy: 0.7527\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0822 - accuracy: 0.7539 - val_loss: 0.5341 - val_accuracy: 0.7580\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0812 - accuracy: 0.7590 - val_loss: 0.5032 - val_accuracy: 0.7731\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0799 - accuracy: 0.7737 - val_loss: 0.4660 - val_accuracy: 0.7886\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0789 - accuracy: 0.7919 - val_loss: 0.4339 - val_accuracy: 0.8048\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 313ms/step - loss: 0.0784 - accuracy: 0.8037 - val_loss: 0.4137 - val_accuracy: 0.8151\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0782 - accuracy: 0.8134 - val_loss: 0.4075 - val_accuracy: 0.8192\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0778 - accuracy: 0.8165 - val_loss: 0.4142 - val_accuracy: 0.8169\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0770 - accuracy: 0.8145 - val_loss: 0.4305 - val_accuracy: 0.8108\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0763 - accuracy: 0.8088 - val_loss: 0.4505 - val_accuracy: 0.8040\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0758 - accuracy: 0.8024 - val_loss: 0.4670 - val_accuracy: 0.7956\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0755 - accuracy: 0.7964 - val_loss: 0.4736 - val_accuracy: 0.7934\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0753 - accuracy: 0.7943 - val_loss: 0.4676 - val_accuracy: 0.7994\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.0749 - accuracy: 0.7974 - val_loss: 0.4517 - val_accuracy: 0.8058\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 0.0744 - accuracy: 0.8040 - val_loss: 0.4315 - val_accuracy: 0.8159\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0739 - accuracy: 0.8141 - val_loss: 0.4135 - val_accuracy: 0.8212\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0737 - accuracy: 0.8206 - val_loss: 0.4025 - val_accuracy: 0.8250\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0736 - accuracy: 0.8244 - val_loss: 0.4005 - val_accuracy: 0.8255\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0733 - accuracy: 0.8259 - val_loss: 0.4070 - val_accuracy: 0.8237\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0730 - accuracy: 0.8246 - val_loss: 0.4189 - val_accuracy: 0.8199\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0727 - accuracy: 0.8195 - val_loss: 0.4316 - val_accuracy: 0.8151\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0725 - accuracy: 0.8136 - val_loss: 0.4399 - val_accuracy: 0.8121\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0723 - accuracy: 0.8088 - val_loss: 0.4406 - val_accuracy: 0.8101\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0722 - accuracy: 0.8081 - val_loss: 0.4335 - val_accuracy: 0.8131\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0719 - accuracy: 0.8118 - val_loss: 0.4218 - val_accuracy: 0.8184\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.0717 - accuracy: 0.8181 - val_loss: 0.4101 - val_accuracy: 0.8232\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0715 - accuracy: 0.8241 - val_loss: 0.4024 - val_accuracy: 0.8260\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0714 - accuracy: 0.8273 - val_loss: 0.4008 - val_accuracy: 0.8275\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0713 - accuracy: 0.8279 - val_loss: 0.4052 - val_accuracy: 0.8250\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0711 - accuracy: 0.8259 - val_loss: 0.4131 - val_accuracy: 0.8217\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.0709 - accuracy: 0.8219 - val_loss: 0.4212 - val_accuracy: 0.8171\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 163ms/step - loss: 0.0708 - accuracy: 0.8172 - val_loss: 0.4257 - val_accuracy: 0.8144\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0707 - accuracy: 0.8141 - val_loss: 0.4249 - val_accuracy: 0.8144\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 0.0705 - accuracy: 0.8144 - val_loss: 0.4192 - val_accuracy: 0.8174\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0704 - accuracy: 0.8179 - val_loss: 0.4112 - val_accuracy: 0.8199\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0703 - accuracy: 0.8217 - val_loss: 0.4044 - val_accuracy: 0.8212\n",
      "5년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1779 - accuracy: 0.8392 - val_loss: 0.7169 - val_accuracy: 0.5694\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1373 - accuracy: 0.5663 - val_loss: 1.0679 - val_accuracy: 0.2714\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1398 - accuracy: 0.2737 - val_loss: 1.1619 - val_accuracy: 0.2291\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1411 - accuracy: 0.2265 - val_loss: 1.0372 - val_accuracy: 0.2975\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1305 - accuracy: 0.3055 - val_loss: 0.8295 - val_accuracy: 0.4586\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.1172 - accuracy: 0.4629 - val_loss: 0.6376 - val_accuracy: 0.6627\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1095 - accuracy: 0.6714 - val_loss: 0.5088 - val_accuracy: 0.7700\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1081 - accuracy: 0.7679 - val_loss: 0.4439 - val_accuracy: 0.8123\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.1082 - accuracy: 0.8030 - val_loss: 0.4255 - val_accuracy: 0.8197\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1056 - accuracy: 0.8093 - val_loss: 0.4403 - val_accuracy: 0.8043\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 0.1002 - accuracy: 0.7967 - val_loss: 0.4811 - val_accuracy: 0.7818\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0948 - accuracy: 0.7726 - val_loss: 0.5392 - val_accuracy: 0.7442\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0916 - accuracy: 0.7383 - val_loss: 0.5992 - val_accuracy: 0.7141\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 0.0906 - accuracy: 0.7105 - val_loss: 0.6421 - val_accuracy: 0.6981\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0907 - accuracy: 0.6957 - val_loss: 0.6546 - val_accuracy: 0.6940\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0902 - accuracy: 0.6923 - val_loss: 0.6350 - val_accuracy: 0.7023\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.0885 - accuracy: 0.7026 - val_loss: 0.5919 - val_accuracy: 0.7256\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0862 - accuracy: 0.7214 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0841 - accuracy: 0.7431 - val_loss: 0.4870 - val_accuracy: 0.7772\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0829 - accuracy: 0.7655 - val_loss: 0.4459 - val_accuracy: 0.7958\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0826 - accuracy: 0.7832 - val_loss: 0.4192 - val_accuracy: 0.8101\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0826 - accuracy: 0.7960 - val_loss: 0.4075 - val_accuracy: 0.8148\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0822 - accuracy: 0.8022 - val_loss: 0.4095 - val_accuracy: 0.8153\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0813 - accuracy: 0.8021 - val_loss: 0.4232 - val_accuracy: 0.8095\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0801 - accuracy: 0.7973 - val_loss: 0.4452 - val_accuracy: 0.8005\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0790 - accuracy: 0.7884 - val_loss: 0.4709 - val_accuracy: 0.7898\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0784 - accuracy: 0.7782 - val_loss: 0.4941 - val_accuracy: 0.7813\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0781 - accuracy: 0.7680 - val_loss: 0.5091 - val_accuracy: 0.7772\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0779 - accuracy: 0.7628 - val_loss: 0.5120 - val_accuracy: 0.7752\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0776 - accuracy: 0.7621 - val_loss: 0.5023 - val_accuracy: 0.7799\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0770 - accuracy: 0.7668 - val_loss: 0.4829 - val_accuracy: 0.7873\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0763 - accuracy: 0.7778 - val_loss: 0.4590 - val_accuracy: 0.7986\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.0756 - accuracy: 0.7890 - val_loss: 0.4357 - val_accuracy: 0.8087\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0753 - accuracy: 0.8007 - val_loss: 0.4173 - val_accuracy: 0.8159\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0751 - accuracy: 0.8086 - val_loss: 0.4064 - val_accuracy: 0.8227\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.0749 - accuracy: 0.8141 - val_loss: 0.4036 - val_accuracy: 0.8241\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0746 - accuracy: 0.8171 - val_loss: 0.4086 - val_accuracy: 0.8235\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 0.0742 - accuracy: 0.8156 - val_loss: 0.4195 - val_accuracy: 0.8189\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 0.0738 - accuracy: 0.8108 - val_loss: 0.4335 - val_accuracy: 0.8134\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0735 - accuracy: 0.8048 - val_loss: 0.4468 - val_accuracy: 0.8095\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 0.0733 - accuracy: 0.7990 - val_loss: 0.4558 - val_accuracy: 0.8071\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0732 - accuracy: 0.7950 - val_loss: 0.4580 - val_accuracy: 0.8063\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.0730 - accuracy: 0.7941 - val_loss: 0.4530 - val_accuracy: 0.8090\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0727 - accuracy: 0.7962 - val_loss: 0.4425 - val_accuracy: 0.8131\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.0724 - accuracy: 0.8025 - val_loss: 0.4293 - val_accuracy: 0.8205\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0722 - accuracy: 0.8100 - val_loss: 0.4170 - val_accuracy: 0.8246\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0720 - accuracy: 0.8167 - val_loss: 0.4082 - val_accuracy: 0.8271\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0719 - accuracy: 0.8211 - val_loss: 0.4044 - val_accuracy: 0.8285\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.0718 - accuracy: 0.8229 - val_loss: 0.4059 - val_accuracy: 0.8274\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 0.0716 - accuracy: 0.8220 - val_loss: 0.4118 - val_accuracy: 0.8244\n",
      "6년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1680 - accuracy: 0.3467 - val_loss: 0.7238 - val_accuracy: 0.5192\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.1469 - accuracy: 0.5255 - val_loss: 0.7703 - val_accuracy: 0.4808\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 0.1324 - accuracy: 0.4832 - val_loss: 0.7484 - val_accuracy: 0.5302\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 0.1236 - accuracy: 0.5323 - val_loss: 0.6544 - val_accuracy: 0.6358\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1161 - accuracy: 0.6302 - val_loss: 0.5835 - val_accuracy: 0.6972\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1100 - accuracy: 0.6945 - val_loss: 0.5635 - val_accuracy: 0.7193\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 0.1041 - accuracy: 0.7163 - val_loss: 0.5721 - val_accuracy: 0.7211\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 0.0990 - accuracy: 0.7175 - val_loss: 0.5765 - val_accuracy: 0.7214\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0950 - accuracy: 0.7203 - val_loss: 0.5576 - val_accuracy: 0.7280\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0918 - accuracy: 0.7348 - val_loss: 0.5257 - val_accuracy: 0.7409\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0894 - accuracy: 0.7532 - val_loss: 0.5010 - val_accuracy: 0.7540\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0876 - accuracy: 0.7642 - val_loss: 0.4937 - val_accuracy: 0.7555\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.0859 - accuracy: 0.7651 - val_loss: 0.4999 - val_accuracy: 0.7516\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.0844 - accuracy: 0.7594 - val_loss: 0.5077 - val_accuracy: 0.7460\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.0831 - accuracy: 0.7546 - val_loss: 0.5056 - val_accuracy: 0.7466\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0819 - accuracy: 0.7573 - val_loss: 0.4917 - val_accuracy: 0.7555\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 1s 575ms/step - loss: 0.0809 - accuracy: 0.7644 - val_loss: 0.4738 - val_accuracy: 0.7687\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 147ms/step - loss: 0.0800 - accuracy: 0.7735 - val_loss: 0.4617 - val_accuracy: 0.7774\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0794 - accuracy: 0.7801 - val_loss: 0.4599 - val_accuracy: 0.7792\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0788 - accuracy: 0.7829 - val_loss: 0.4658 - val_accuracy: 0.7774\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0782 - accuracy: 0.7825 - val_loss: 0.4718 - val_accuracy: 0.7768\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0776 - accuracy: 0.7812 - val_loss: 0.4710 - val_accuracy: 0.7810\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.0769 - accuracy: 0.7831 - val_loss: 0.4624 - val_accuracy: 0.7837\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0762 - accuracy: 0.7885 - val_loss: 0.4511 - val_accuracy: 0.7896\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0755 - accuracy: 0.7931 - val_loss: 0.4435 - val_accuracy: 0.7935\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0749 - accuracy: 0.7996 - val_loss: 0.4430 - val_accuracy: 0.7971\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.0744 - accuracy: 0.8024 - val_loss: 0.4476 - val_accuracy: 0.7950\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0739 - accuracy: 0.8026 - val_loss: 0.4519 - val_accuracy: 0.7953\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0735 - accuracy: 0.8029 - val_loss: 0.4510 - val_accuracy: 0.7974\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0731 - accuracy: 0.8052 - val_loss: 0.4445 - val_accuracy: 0.7998\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0728 - accuracy: 0.8078 - val_loss: 0.4368 - val_accuracy: 0.8031\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0724 - accuracy: 0.8118 - val_loss: 0.4325 - val_accuracy: 0.8043\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0721 - accuracy: 0.8148 - val_loss: 0.4331 - val_accuracy: 0.8043\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0717 - accuracy: 0.8146 - val_loss: 0.4360 - val_accuracy: 0.8034\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0714 - accuracy: 0.8145 - val_loss: 0.4366 - val_accuracy: 0.8040\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0711 - accuracy: 0.8144 - val_loss: 0.4329 - val_accuracy: 0.8061\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0708 - accuracy: 0.8160 - val_loss: 0.4267 - val_accuracy: 0.8067\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0705 - accuracy: 0.8175 - val_loss: 0.4222 - val_accuracy: 0.8088\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0703 - accuracy: 0.8190 - val_loss: 0.4219 - val_accuracy: 0.8082\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0700 - accuracy: 0.8196 - val_loss: 0.4243 - val_accuracy: 0.8073\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0698 - accuracy: 0.8190 - val_loss: 0.4259 - val_accuracy: 0.8064\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0695 - accuracy: 0.8184 - val_loss: 0.4239 - val_accuracy: 0.8064\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 497ms/step - loss: 0.0693 - accuracy: 0.8201 - val_loss: 0.4197 - val_accuracy: 0.8091\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0691 - accuracy: 0.8222 - val_loss: 0.4166 - val_accuracy: 0.8097\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0689 - accuracy: 0.8236 - val_loss: 0.4168 - val_accuracy: 0.8088\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0686 - accuracy: 0.8241 - val_loss: 0.4190 - val_accuracy: 0.8091\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0684 - accuracy: 0.8235 - val_loss: 0.4200 - val_accuracy: 0.8091\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0682 - accuracy: 0.8229 - val_loss: 0.4181 - val_accuracy: 0.8097\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0680 - accuracy: 0.8238 - val_loss: 0.4147 - val_accuracy: 0.8103\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0678 - accuracy: 0.8243 - val_loss: 0.4126 - val_accuracy: 0.8109\n",
      "7년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1702 - accuracy: 0.7715 - val_loss: 1.0023 - val_accuracy: 0.2748\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1476 - accuracy: 0.2670 - val_loss: 1.1464 - val_accuracy: 0.1907\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1471 - accuracy: 0.1889 - val_loss: 0.9797 - val_accuracy: 0.2925\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.1341 - accuracy: 0.2940 - val_loss: 0.7458 - val_accuracy: 0.5519\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.1229 - accuracy: 0.5405 - val_loss: 0.5821 - val_accuracy: 0.7134\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1204 - accuracy: 0.7158 - val_loss: 0.5138 - val_accuracy: 0.7636\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1196 - accuracy: 0.7664 - val_loss: 0.5123 - val_accuracy: 0.7594\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1148 - accuracy: 0.7667 - val_loss: 0.5561 - val_accuracy: 0.7262\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1083 - accuracy: 0.7361 - val_loss: 0.6268 - val_accuracy: 0.6871\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1041 - accuracy: 0.6911 - val_loss: 0.6940 - val_accuracy: 0.6507\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1026 - accuracy: 0.6485 - val_loss: 0.7237 - val_accuracy: 0.6343\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1016 - accuracy: 0.6347 - val_loss: 0.7026 - val_accuracy: 0.6513\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0991 - accuracy: 0.6524 - val_loss: 0.6440 - val_accuracy: 0.6878\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0956 - accuracy: 0.6904 - val_loss: 0.5735 - val_accuracy: 0.7249\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0927 - accuracy: 0.7309 - val_loss: 0.5131 - val_accuracy: 0.7554\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0911 - accuracy: 0.7602 - val_loss: 0.4747 - val_accuracy: 0.7754\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0903 - accuracy: 0.7805 - val_loss: 0.4605 - val_accuracy: 0.7820\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0892 - accuracy: 0.7887 - val_loss: 0.4678 - val_accuracy: 0.7781\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0874 - accuracy: 0.7850 - val_loss: 0.4919 - val_accuracy: 0.7656\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.0855 - accuracy: 0.7735 - val_loss: 0.5245 - val_accuracy: 0.7462\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0844 - accuracy: 0.7593 - val_loss: 0.5541 - val_accuracy: 0.7344\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 0.0839 - accuracy: 0.7474 - val_loss: 0.5692 - val_accuracy: 0.7272\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0836 - accuracy: 0.7427 - val_loss: 0.5639 - val_accuracy: 0.7321\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0828 - accuracy: 0.7458 - val_loss: 0.5408 - val_accuracy: 0.7459\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0818 - accuracy: 0.7560 - val_loss: 0.5088 - val_accuracy: 0.7590\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0808 - accuracy: 0.7709 - val_loss: 0.4780 - val_accuracy: 0.7751\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.0801 - accuracy: 0.7854 - val_loss: 0.4558 - val_accuracy: 0.7850\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 0.0797 - accuracy: 0.7945 - val_loss: 0.4458 - val_accuracy: 0.7902\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0792 - accuracy: 0.7997 - val_loss: 0.4483 - val_accuracy: 0.7905\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.0785 - accuracy: 0.7991 - val_loss: 0.4606 - val_accuracy: 0.7859\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0777 - accuracy: 0.7948 - val_loss: 0.4780 - val_accuracy: 0.7817\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0771 - accuracy: 0.7857 - val_loss: 0.4938 - val_accuracy: 0.7738\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0767 - accuracy: 0.7807 - val_loss: 0.5018 - val_accuracy: 0.7708\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0763 - accuracy: 0.7792 - val_loss: 0.4987 - val_accuracy: 0.7725\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0759 - accuracy: 0.7808 - val_loss: 0.4857 - val_accuracy: 0.7787\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0753 - accuracy: 0.7862 - val_loss: 0.4676 - val_accuracy: 0.7876\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0748 - accuracy: 0.7947 - val_loss: 0.4502 - val_accuracy: 0.7968\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0745 - accuracy: 0.8038 - val_loss: 0.4384 - val_accuracy: 0.8020\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0742 - accuracy: 0.8100 - val_loss: 0.4346 - val_accuracy: 0.8043\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0738 - accuracy: 0.8121 - val_loss: 0.4385 - val_accuracy: 0.8030\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.0734 - accuracy: 0.8108 - val_loss: 0.4478 - val_accuracy: 0.7997\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0730 - accuracy: 0.8071 - val_loss: 0.4584 - val_accuracy: 0.7942\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0727 - accuracy: 0.8032 - val_loss: 0.4656 - val_accuracy: 0.7915\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0724 - accuracy: 0.8015 - val_loss: 0.4663 - val_accuracy: 0.7902\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0721 - accuracy: 0.8022 - val_loss: 0.4598 - val_accuracy: 0.7935\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0718 - accuracy: 0.8050 - val_loss: 0.4488 - val_accuracy: 0.8001\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.0714 - accuracy: 0.8091 - val_loss: 0.4371 - val_accuracy: 0.8076\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0712 - accuracy: 0.8153 - val_loss: 0.4287 - val_accuracy: 0.8106\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0710 - accuracy: 0.8181 - val_loss: 0.4258 - val_accuracy: 0.8116\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0707 - accuracy: 0.8203 - val_loss: 0.4284 - val_accuracy: 0.8122\n",
      "8년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1759 - accuracy: 0.1513 - val_loss: 0.7274 - val_accuracy: 0.5305\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.1438 - accuracy: 0.5215 - val_loss: 0.4971 - val_accuracy: 0.7957\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 0.1508 - accuracy: 0.7873 - val_loss: 0.4957 - val_accuracy: 0.7964\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.1398 - accuracy: 0.7922 - val_loss: 0.5907 - val_accuracy: 0.7079\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 0.1242 - accuracy: 0.6972 - val_loss: 0.7427 - val_accuracy: 0.5312\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1181 - accuracy: 0.5367 - val_loss: 0.8591 - val_accuracy: 0.4194\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1182 - accuracy: 0.4308 - val_loss: 0.8646 - val_accuracy: 0.4372\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1156 - accuracy: 0.4496 - val_loss: 0.7738 - val_accuracy: 0.5530\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1089 - accuracy: 0.5603 - val_loss: 0.6463 - val_accuracy: 0.6767\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1025 - accuracy: 0.6780 - val_loss: 0.5351 - val_accuracy: 0.7580\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0995 - accuracy: 0.7570 - val_loss: 0.4650 - val_accuracy: 0.7910\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 0.0992 - accuracy: 0.7907 - val_loss: 0.4362 - val_accuracy: 0.8033\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 158ms/step - loss: 0.0986 - accuracy: 0.8016 - val_loss: 0.4410 - val_accuracy: 0.8001\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0961 - accuracy: 0.7997 - val_loss: 0.4724 - val_accuracy: 0.7834\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0928 - accuracy: 0.7814 - val_loss: 0.5218 - val_accuracy: 0.7518\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0905 - accuracy: 0.7536 - val_loss: 0.5748 - val_accuracy: 0.7199\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0897 - accuracy: 0.7283 - val_loss: 0.6128 - val_accuracy: 0.6999\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0897 - accuracy: 0.7099 - val_loss: 0.6216 - val_accuracy: 0.6963\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0891 - accuracy: 0.7061 - val_loss: 0.6000 - val_accuracy: 0.7079\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0877 - accuracy: 0.7171 - val_loss: 0.5576 - val_accuracy: 0.7275\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 0.0860 - accuracy: 0.7366 - val_loss: 0.5093 - val_accuracy: 0.7569\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0848 - accuracy: 0.7604 - val_loss: 0.4680 - val_accuracy: 0.7769\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0843 - accuracy: 0.7796 - val_loss: 0.4412 - val_accuracy: 0.7968\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0841 - accuracy: 0.7921 - val_loss: 0.4313 - val_accuracy: 0.8048\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0837 - accuracy: 0.7976 - val_loss: 0.4375 - val_accuracy: 0.8001\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0827 - accuracy: 0.7953 - val_loss: 0.4565 - val_accuracy: 0.7892\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0816 - accuracy: 0.7876 - val_loss: 0.4827 - val_accuracy: 0.7769\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0807 - accuracy: 0.7741 - val_loss: 0.5078 - val_accuracy: 0.7642\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0803 - accuracy: 0.7632 - val_loss: 0.5233 - val_accuracy: 0.7562\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0800 - accuracy: 0.7584 - val_loss: 0.5238 - val_accuracy: 0.7594\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0795 - accuracy: 0.7580 - val_loss: 0.5093 - val_accuracy: 0.7678\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0788 - accuracy: 0.7669 - val_loss: 0.4851 - val_accuracy: 0.7801\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0780 - accuracy: 0.7806 - val_loss: 0.4590 - val_accuracy: 0.7961\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.0775 - accuracy: 0.7933 - val_loss: 0.4378 - val_accuracy: 0.8081\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0772 - accuracy: 0.8021 - val_loss: 0.4260 - val_accuracy: 0.8139\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0769 - accuracy: 0.8086 - val_loss: 0.4249 - val_accuracy: 0.8157\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 303ms/step - loss: 0.0765 - accuracy: 0.8102 - val_loss: 0.4333 - val_accuracy: 0.8128\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0759 - accuracy: 0.8074 - val_loss: 0.4477 - val_accuracy: 0.8062\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0754 - accuracy: 0.8004 - val_loss: 0.4629 - val_accuracy: 0.8001\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.0751 - accuracy: 0.7952 - val_loss: 0.4731 - val_accuracy: 0.7972\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0749 - accuracy: 0.7919 - val_loss: 0.4743 - val_accuracy: 0.7986\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0746 - accuracy: 0.7922 - val_loss: 0.4660 - val_accuracy: 0.8012\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0742 - accuracy: 0.7967 - val_loss: 0.4513 - val_accuracy: 0.8106\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0738 - accuracy: 0.8026 - val_loss: 0.4354 - val_accuracy: 0.8168\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0735 - accuracy: 0.8101 - val_loss: 0.4230 - val_accuracy: 0.8197\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0733 - accuracy: 0.8163 - val_loss: 0.4173 - val_accuracy: 0.8208\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0731 - accuracy: 0.8190 - val_loss: 0.4189 - val_accuracy: 0.8197\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0728 - accuracy: 0.8180 - val_loss: 0.4263 - val_accuracy: 0.8197\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0725 - accuracy: 0.8156 - val_loss: 0.4361 - val_accuracy: 0.8168\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0722 - accuracy: 0.8109 - val_loss: 0.4440 - val_accuracy: 0.8157\n",
      "9년도 데이터 훈련시작\n",
      "Epoch 1/50\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1617 - accuracy: 0.4674 - val_loss: 0.6982 - val_accuracy: 0.5950\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 457ms/step - loss: 0.1377 - accuracy: 0.6048 - val_loss: 0.7456 - val_accuracy: 0.5392\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 0.1250 - accuracy: 0.5452 - val_loss: 0.7563 - val_accuracy: 0.5319\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.1207 - accuracy: 0.5462 - val_loss: 0.6756 - val_accuracy: 0.6172\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 0.1166 - accuracy: 0.6246 - val_loss: 0.6129 - val_accuracy: 0.6730\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 0.1118 - accuracy: 0.6820 - val_loss: 0.5975 - val_accuracy: 0.6884\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 0.1058 - accuracy: 0.6975 - val_loss: 0.6059 - val_accuracy: 0.6835\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1004 - accuracy: 0.6945 - val_loss: 0.6048 - val_accuracy: 0.6948\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0964 - accuracy: 0.7002 - val_loss: 0.5803 - val_accuracy: 0.7106\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0936 - accuracy: 0.7154 - val_loss: 0.5476 - val_accuracy: 0.7352\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.0917 - accuracy: 0.7372 - val_loss: 0.5273 - val_accuracy: 0.7522\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0903 - accuracy: 0.7469 - val_loss: 0.5252 - val_accuracy: 0.7526\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0888 - accuracy: 0.7491 - val_loss: 0.5329 - val_accuracy: 0.7478\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0871 - accuracy: 0.7459 - val_loss: 0.5357 - val_accuracy: 0.7466\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0854 - accuracy: 0.7439 - val_loss: 0.5250 - val_accuracy: 0.7518\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0839 - accuracy: 0.7487 - val_loss: 0.5046 - val_accuracy: 0.7619\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0827 - accuracy: 0.7615 - val_loss: 0.4867 - val_accuracy: 0.7716\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0819 - accuracy: 0.7725 - val_loss: 0.4805 - val_accuracy: 0.7761\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0813 - accuracy: 0.7752 - val_loss: 0.4859 - val_accuracy: 0.7741\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0806 - accuracy: 0.7753 - val_loss: 0.4944 - val_accuracy: 0.7704\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0800 - accuracy: 0.7752 - val_loss: 0.4961 - val_accuracy: 0.7704\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0792 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7765\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0782 - accuracy: 0.7819 - val_loss: 0.4744 - val_accuracy: 0.7829\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0773 - accuracy: 0.7903 - val_loss: 0.4650 - val_accuracy: 0.7866\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0765 - accuracy: 0.7954 - val_loss: 0.4643 - val_accuracy: 0.7890\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0757 - accuracy: 0.7982 - val_loss: 0.4702 - val_accuracy: 0.7878\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0751 - accuracy: 0.7987 - val_loss: 0.4759 - val_accuracy: 0.7854\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0746 - accuracy: 0.7979 - val_loss: 0.4751 - val_accuracy: 0.7878\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0742 - accuracy: 0.7997 - val_loss: 0.4674 - val_accuracy: 0.7922\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0737 - accuracy: 0.8048 - val_loss: 0.4581 - val_accuracy: 0.7963\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0731 - accuracy: 0.8093 - val_loss: 0.4531 - val_accuracy: 0.8003\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0726 - accuracy: 0.8126 - val_loss: 0.4535 - val_accuracy: 0.8003\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0720 - accuracy: 0.8132 - val_loss: 0.4556 - val_accuracy: 0.8003\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0715 - accuracy: 0.8131 - val_loss: 0.4543 - val_accuracy: 0.8007\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0711 - accuracy: 0.8130 - val_loss: 0.4481 - val_accuracy: 0.8023\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0707 - accuracy: 0.8145 - val_loss: 0.4405 - val_accuracy: 0.8040\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0704 - accuracy: 0.8178 - val_loss: 0.4362 - val_accuracy: 0.8036\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.0700 - accuracy: 0.8209 - val_loss: 0.4369 - val_accuracy: 0.8032\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.0697 - accuracy: 0.8223 - val_loss: 0.4394 - val_accuracy: 0.8052\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0693 - accuracy: 0.8216 - val_loss: 0.4390 - val_accuracy: 0.8060\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 0.0690 - accuracy: 0.8227 - val_loss: 0.4346 - val_accuracy: 0.8076\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0686 - accuracy: 0.8247 - val_loss: 0.4295 - val_accuracy: 0.8137\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0683 - accuracy: 0.8272 - val_loss: 0.4276 - val_accuracy: 0.8145\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0680 - accuracy: 0.8275 - val_loss: 0.4293 - val_accuracy: 0.8129\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0677 - accuracy: 0.8279 - val_loss: 0.4311 - val_accuracy: 0.8133\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0675 - accuracy: 0.8280 - val_loss: 0.4295 - val_accuracy: 0.8137\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0672 - accuracy: 0.8288 - val_loss: 0.4250 - val_accuracy: 0.8169\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0669 - accuracy: 0.8300 - val_loss: 0.4211 - val_accuracy: 0.8177\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0666 - accuracy: 0.8311 - val_loss: 0.4204 - val_accuracy: 0.8169\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0663 - accuracy: 0.8306 - val_loss: 0.4218 - val_accuracy: 0.8157\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "result = {}\n",
    "valid = True\n",
    "\n",
    "# 파일명 읽어오기\n",
    "data_path = os.path.join(\".\",\"final_data\")\n",
    "file_names = os.listdir(data_path)\n",
    "\n",
    "# 하이퍼 파라미터 지정\n",
    "learning_rate = 1e-4\n",
    "max_epoch = 50\n",
    "\n",
    "for idx, file_name in enumerate(file_names):\n",
    "    # 해당 파일의 년도 추출\n",
    "    term = int(file_name.split(\"y\")[0])\n",
    "    print(f\"{term}년도 데이터 훈련시작\")\n",
    "    \n",
    "    # 데이터 분할\n",
    "    X_train,X_valid,X_test, y_train,y_valid,y_test = train_test_valid(file_name, valid=True)\n",
    "    \n",
    "    # 모델 구현\n",
    "    input_ = keras.layers.Input(shape = [X_train.shape[1]])\n",
    "    input2_ = keras.layers.Input(shape = (10*term))\n",
    "    hidden_layer1 = keras.layers.Dense(512, activation = \"selu\", kernel_initializer=lucun_init)(input_)\n",
    "    hidden_layer2 = keras.layers.Dense(512, activation = \"selu\", kernel_initializer=lucun_init)(hidden_layer1)\n",
    "    concat = keras.layers.concatenate([hidden_layer2, input2_])\n",
    "    hidden_layer3 = keras.layers.Dense(256, activation = \"selu\", kernel_initializer=lucun_init)(concat)\n",
    "    output_layer = keras.layers.Dense(1, activation = \"sigmoid\")(hidden_layer3)\n",
    "    models.append(keras.Model(inputs = [input_, input2_], outputs = [output_layer]))\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    models[idx].compile(loss=\"binary_crossentropy\", metrics=\"accuracy\", optimizer = keras.optimizers.Adam(lr=learning_rate))\n",
    "    \n",
    "    # 모델 훈련\n",
    "    history = models[idx].fit(x=[X_train,X_train[:,-10*term:]],y=y_train, epochs = max_epoch, \n",
    "                           validation_data = ((X_valid,X_valid[:,-10*term:]),y_valid),\n",
    "                       class_weight = {0:0.1, 1:0.9}, batch_size = X_train.shape[0],validation_batch_size=X_valid.shape[0])\n",
    "    \n",
    "    # 모델 평가\n",
    "    a={i:j for i,j in zip([\"accuracy\", \"precision\", \"recall\", \"confusion\", \"roc\"],get_score(X_test,y_test,term,models[idx]))}\n",
    "    result[f\"{term}year\"]=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10year</th>\n",
       "      <th>11year</th>\n",
       "      <th>12year</th>\n",
       "      <th>13year</th>\n",
       "      <th>14year</th>\n",
       "      <th>15year</th>\n",
       "      <th>16year</th>\n",
       "      <th>17year</th>\n",
       "      <th>18year</th>\n",
       "      <th>1year</th>\n",
       "      <th>2year</th>\n",
       "      <th>3year</th>\n",
       "      <th>4year</th>\n",
       "      <th>5year</th>\n",
       "      <th>6year</th>\n",
       "      <th>7year</th>\n",
       "      <th>8year</th>\n",
       "      <th>9year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.816148</td>\n",
       "      <td>0.80902</td>\n",
       "      <td>0.816084</td>\n",
       "      <td>0.775641</td>\n",
       "      <td>0.82141</td>\n",
       "      <td>0.824315</td>\n",
       "      <td>0.850596</td>\n",
       "      <td>0.833799</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.808764</td>\n",
       "      <td>0.793526</td>\n",
       "      <td>0.819522</td>\n",
       "      <td>0.824886</td>\n",
       "      <td>0.817224</td>\n",
       "      <td>0.815978</td>\n",
       "      <td>0.81623</td>\n",
       "      <td>0.80688</td>\n",
       "      <td>0.824885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.377114</td>\n",
       "      <td>0.373453</td>\n",
       "      <td>0.378747</td>\n",
       "      <td>0.304161</td>\n",
       "      <td>0.362105</td>\n",
       "      <td>0.358491</td>\n",
       "      <td>0.382488</td>\n",
       "      <td>0.375758</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.373707</td>\n",
       "      <td>0.344523</td>\n",
       "      <td>0.373997</td>\n",
       "      <td>0.38273</td>\n",
       "      <td>0.368649</td>\n",
       "      <td>0.389527</td>\n",
       "      <td>0.374363</td>\n",
       "      <td>0.370256</td>\n",
       "      <td>0.380604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.887588</td>\n",
       "      <td>0.85347</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.84127</td>\n",
       "      <td>0.815166</td>\n",
       "      <td>0.841772</td>\n",
       "      <td>0.741071</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.880203</td>\n",
       "      <td>0.888383</td>\n",
       "      <td>0.858722</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.867347</td>\n",
       "      <td>0.89838</td>\n",
       "      <td>0.87415</td>\n",
       "      <td>0.865942</td>\n",
       "      <td>0.902386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>confusion</th>\n",
       "      <td>[[2613, 626], [48, 379]]</td>\n",
       "      <td>[[2269, 557], [57, 332]]</td>\n",
       "      <td>[[1985, 456], [54, 278]]</td>\n",
       "      <td>[[1603, 485], [40, 212]]</td>\n",
       "      <td>[[1401, 303], [39, 172]]</td>\n",
       "      <td>[[1101, 238], [25, 133]]</td>\n",
       "      <td>[[845, 134], [29, 83]]</td>\n",
       "      <td>[[535, 103], [16, 62]]</td>\n",
       "      <td>[[260, 54], [9, 28]]</td>\n",
       "      <td>[[5777, 1453], [118, 867]]</td>\n",
       "      <td>[[5300, 1484], [98, 780]]</td>\n",
       "      <td>[[5136, 1170], [115, 699]]</td>\n",
       "      <td>[[4780, 1058], [96, 656]]</td>\n",
       "      <td>[[4368, 1019], [91, 595]]</td>\n",
       "      <td>[[3935, 956], [69, 610]]</td>\n",
       "      <td>[[3630, 859], [74, 514]]</td>\n",
       "      <td>[[3228, 813], [74, 478]]</td>\n",
       "      <td>[[2985, 677], [45, 416]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.847159</td>\n",
       "      <td>0.828186</td>\n",
       "      <td>0.82527</td>\n",
       "      <td>0.804495</td>\n",
       "      <td>0.818674</td>\n",
       "      <td>0.832014</td>\n",
       "      <td>0.802099</td>\n",
       "      <td>0.816715</td>\n",
       "      <td>0.792391</td>\n",
       "      <td>0.839617</td>\n",
       "      <td>0.834816</td>\n",
       "      <td>0.836592</td>\n",
       "      <td>0.845557</td>\n",
       "      <td>0.839094</td>\n",
       "      <td>0.851459</td>\n",
       "      <td>0.841397</td>\n",
       "      <td>0.832377</td>\n",
       "      <td>0.858757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             10year                    11year  \\\n",
       "accuracy                   0.816148                   0.80902   \n",
       "precision                  0.377114                  0.373453   \n",
       "recall                     0.887588                   0.85347   \n",
       "confusion  [[2613, 626], [48, 379]]  [[2269, 557], [57, 332]]   \n",
       "roc                        0.847159                  0.828186   \n",
       "\n",
       "                             12year                    13year  \\\n",
       "accuracy                   0.816084                  0.775641   \n",
       "precision                  0.378747                  0.304161   \n",
       "recall                     0.837349                   0.84127   \n",
       "confusion  [[1985, 456], [54, 278]]  [[1603, 485], [40, 212]]   \n",
       "roc                         0.82527                  0.804495   \n",
       "\n",
       "                             14year                    15year  \\\n",
       "accuracy                    0.82141                  0.824315   \n",
       "precision                  0.362105                  0.358491   \n",
       "recall                     0.815166                  0.841772   \n",
       "confusion  [[1401, 303], [39, 172]]  [[1101, 238], [25, 133]]   \n",
       "roc                        0.818674                  0.832014   \n",
       "\n",
       "                           16year                  17year  \\\n",
       "accuracy                 0.850596                0.833799   \n",
       "precision                0.382488                0.375758   \n",
       "recall                   0.741071                0.794872   \n",
       "confusion  [[845, 134], [29, 83]]  [[535, 103], [16, 62]]   \n",
       "roc                      0.802099                0.816715   \n",
       "\n",
       "                         18year                       1year  \\\n",
       "accuracy               0.820513                    0.808764   \n",
       "precision              0.341463                    0.373707   \n",
       "recall                 0.756757                    0.880203   \n",
       "confusion  [[260, 54], [9, 28]]  [[5777, 1453], [118, 867]]   \n",
       "roc                    0.792391                    0.839617   \n",
       "\n",
       "                               2year                       3year  \\\n",
       "accuracy                    0.793526                    0.819522   \n",
       "precision                   0.344523                    0.373997   \n",
       "recall                      0.888383                    0.858722   \n",
       "confusion  [[5300, 1484], [98, 780]]  [[5136, 1170], [115, 699]]   \n",
       "roc                         0.834816                    0.836592   \n",
       "\n",
       "                               4year                      5year  \\\n",
       "accuracy                    0.824886                   0.817224   \n",
       "precision                    0.38273                   0.368649   \n",
       "recall                       0.87234                   0.867347   \n",
       "confusion  [[4780, 1058], [96, 656]]  [[4368, 1019], [91, 595]]   \n",
       "roc                         0.845557                   0.839094   \n",
       "\n",
       "                              6year                     7year  \\\n",
       "accuracy                   0.815978                   0.81623   \n",
       "precision                  0.389527                  0.374363   \n",
       "recall                      0.89838                   0.87415   \n",
       "confusion  [[3935, 956], [69, 610]]  [[3630, 859], [74, 514]]   \n",
       "roc                        0.851459                  0.841397   \n",
       "\n",
       "                              8year                     9year  \n",
       "accuracy                    0.80688                  0.824885  \n",
       "precision                  0.370256                  0.380604  \n",
       "recall                     0.865942                  0.902386  \n",
       "confusion  [[3228, 813], [74, 478]]  [[2985, 677], [45, 416]]  \n",
       "roc                        0.832377                  0.858757  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a=[f\"{i}year\" for i in range(1,19)]\n",
    "result_df = pd.DataFrame(result)[a]\n",
    "\n",
    "result_df.T.plot()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 9개년의 recall이 가장 높음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9개년 데이터를 사용한 MLP 최종 모델\n",
    "- best_term : 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"final_tensorboard\")\n",
    "\n",
    "# 루트 로그 디렉터리와 현재 날짜와 시간을 이용한 서브 디렉터리 생성하는 함수\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id) # 디렉토리 주소를 반환\n",
    "\n",
    "run_logdir = get_run_logdir() # 새로 그래프를 생성하려고 할 때마다 이 것을 실행해 주어야 함 \n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"final_mlp_best_model.h5\",\n",
    "                                               save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1771 - accuracy: 0.7067 - val_loss: 1.0375 - val_accuracy: 0.3350\n",
      "Epoch 2/100\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1541 - accuracy: 0.3356 - val_loss: 1.2129 - val_accuracy: 0.2302\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1547 - accuracy: 0.2305 - val_loss: 1.0531 - val_accuracy: 0.2789\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 0.1416 - accuracy: 0.2790 - val_loss: 0.7977 - val_accuracy: 0.4625\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 0.1280 - accuracy: 0.4627 - val_loss: 0.6006 - val_accuracy: 0.6772\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1232 - accuracy: 0.6793 - val_loss: 0.5080 - val_accuracy: 0.7732\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.1214 - accuracy: 0.7747 - val_loss: 0.4941 - val_accuracy: 0.7793\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.1156 - accuracy: 0.7832 - val_loss: 0.5333 - val_accuracy: 0.7415\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1079 - accuracy: 0.7414 - val_loss: 0.6052 - val_accuracy: 0.6750\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1029 - accuracy: 0.6787 - val_loss: 0.6750 - val_accuracy: 0.6270\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.1012 - accuracy: 0.6280 - val_loss: 0.7035 - val_accuracy: 0.6141\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1000 - accuracy: 0.6118 - val_loss: 0.6775 - val_accuracy: 0.6381\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0972 - accuracy: 0.6391 - val_loss: 0.6135 - val_accuracy: 0.6825\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0936 - accuracy: 0.6853 - val_loss: 0.5399 - val_accuracy: 0.7259\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0908 - accuracy: 0.7342 - val_loss: 0.4797 - val_accuracy: 0.7662\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 0.0895 - accuracy: 0.7654 - val_loss: 0.4437 - val_accuracy: 0.7885\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0890 - accuracy: 0.7847 - val_loss: 0.4330 - val_accuracy: 0.7953\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0879 - accuracy: 0.7902 - val_loss: 0.4444 - val_accuracy: 0.7878\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0861 - accuracy: 0.7845 - val_loss: 0.4719 - val_accuracy: 0.7740\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.0844 - accuracy: 0.7711 - val_loss: 0.5066 - val_accuracy: 0.7541\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.0834 - accuracy: 0.7554 - val_loss: 0.5361 - val_accuracy: 0.7390\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0830 - accuracy: 0.7439 - val_loss: 0.5493 - val_accuracy: 0.7334\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0826 - accuracy: 0.7389 - val_loss: 0.5416 - val_accuracy: 0.7388\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0818 - accuracy: 0.7435 - val_loss: 0.5167 - val_accuracy: 0.7555\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0806 - accuracy: 0.7567 - val_loss: 0.4837 - val_accuracy: 0.7720\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0796 - accuracy: 0.7713 - val_loss: 0.4528 - val_accuracy: 0.7875\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0790 - accuracy: 0.7861 - val_loss: 0.4313 - val_accuracy: 0.7977\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0787 - accuracy: 0.7985 - val_loss: 0.4225 - val_accuracy: 0.8035\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0782 - accuracy: 0.8025 - val_loss: 0.4262 - val_accuracy: 0.8016\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0775 - accuracy: 0.8017 - val_loss: 0.4399 - val_accuracy: 0.7938\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0767 - accuracy: 0.7974 - val_loss: 0.4583 - val_accuracy: 0.7870\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0761 - accuracy: 0.7889 - val_loss: 0.4746 - val_accuracy: 0.7790\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.0757 - accuracy: 0.7823 - val_loss: 0.4824 - val_accuracy: 0.7769\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0754 - accuracy: 0.7810 - val_loss: 0.4784 - val_accuracy: 0.7790\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.0749 - accuracy: 0.7834 - val_loss: 0.4642 - val_accuracy: 0.7863\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0743 - accuracy: 0.7908 - val_loss: 0.4450 - val_accuracy: 0.7972\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0737 - accuracy: 0.7995 - val_loss: 0.4270 - val_accuracy: 0.8048\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0733 - accuracy: 0.8094 - val_loss: 0.4152 - val_accuracy: 0.8128\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0730 - accuracy: 0.8152 - val_loss: 0.4120 - val_accuracy: 0.8137\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0726 - accuracy: 0.8175 - val_loss: 0.4169 - val_accuracy: 0.8111\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0721 - accuracy: 0.8160 - val_loss: 0.4273 - val_accuracy: 0.8086\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0717 - accuracy: 0.8133 - val_loss: 0.4385 - val_accuracy: 0.8055\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0713 - accuracy: 0.8095 - val_loss: 0.4456 - val_accuracy: 0.8045\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.0711 - accuracy: 0.8069 - val_loss: 0.4454 - val_accuracy: 0.8060\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.0707 - accuracy: 0.8091 - val_loss: 0.4379 - val_accuracy: 0.8096\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0704 - accuracy: 0.8131 - val_loss: 0.4261 - val_accuracy: 0.8125\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.0700 - accuracy: 0.8193 - val_loss: 0.4145 - val_accuracy: 0.8179\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0698 - accuracy: 0.8245 - val_loss: 0.4069 - val_accuracy: 0.8212\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.0695 - accuracy: 0.8264 - val_loss: 0.4053 - val_accuracy: 0.8229\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0692 - accuracy: 0.8275 - val_loss: 0.4091 - val_accuracy: 0.8225\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.0689 - accuracy: 0.8273 - val_loss: 0.4161 - val_accuracy: 0.8188\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.0687 - accuracy: 0.8255 - val_loss: 0.4226 - val_accuracy: 0.8179\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.0684 - accuracy: 0.8241 - val_loss: 0.4252 - val_accuracy: 0.8169\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0682 - accuracy: 0.8236 - val_loss: 0.4226 - val_accuracy: 0.8193\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.0680 - accuracy: 0.8250 - val_loss: 0.4158 - val_accuracy: 0.8227\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0677 - accuracy: 0.8269 - val_loss: 0.4076 - val_accuracy: 0.8249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 0.0675 - accuracy: 0.8302 - val_loss: 0.4012 - val_accuracy: 0.8273\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0673 - accuracy: 0.8334 - val_loss: 0.3989 - val_accuracy: 0.8283\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0671 - accuracy: 0.8338 - val_loss: 0.4006 - val_accuracy: 0.8268\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0669 - accuracy: 0.8336 - val_loss: 0.4050 - val_accuracy: 0.8259\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0667 - accuracy: 0.8326 - val_loss: 0.4094 - val_accuracy: 0.8242\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.0665 - accuracy: 0.8311 - val_loss: 0.4112 - val_accuracy: 0.8237\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 0.0663 - accuracy: 0.8305 - val_loss: 0.4094 - val_accuracy: 0.8239\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0661 - accuracy: 0.8307 - val_loss: 0.4047 - val_accuracy: 0.8254\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.0659 - accuracy: 0.8321 - val_loss: 0.3993 - val_accuracy: 0.8276\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 0.0658 - accuracy: 0.8338 - val_loss: 0.3954 - val_accuracy: 0.8295\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.0656 - accuracy: 0.8351 - val_loss: 0.3945 - val_accuracy: 0.8295\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.0654 - accuracy: 0.8352 - val_loss: 0.3962 - val_accuracy: 0.8288\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.0653 - accuracy: 0.8340 - val_loss: 0.3993 - val_accuracy: 0.8271\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0651 - accuracy: 0.8324 - val_loss: 0.4017 - val_accuracy: 0.8263\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0650 - accuracy: 0.8317 - val_loss: 0.4018 - val_accuracy: 0.8263\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.0648 - accuracy: 0.8316 - val_loss: 0.3995 - val_accuracy: 0.8263\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.0647 - accuracy: 0.8323 - val_loss: 0.3957 - val_accuracy: 0.8273\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0645 - accuracy: 0.8330 - val_loss: 0.3924 - val_accuracy: 0.8290\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.0644 - accuracy: 0.8339 - val_loss: 0.3909 - val_accuracy: 0.8290\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.0643 - accuracy: 0.8342 - val_loss: 0.3915 - val_accuracy: 0.8295\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0641 - accuracy: 0.8339 - val_loss: 0.3934 - val_accuracy: 0.8283\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.0640 - accuracy: 0.8334 - val_loss: 0.3951 - val_accuracy: 0.8263\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0639 - accuracy: 0.8330 - val_loss: 0.3954 - val_accuracy: 0.8263\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0638 - accuracy: 0.8325 - val_loss: 0.3939 - val_accuracy: 0.8276\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0636 - accuracy: 0.8331 - val_loss: 0.3913 - val_accuracy: 0.8295\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0635 - accuracy: 0.8337 - val_loss: 0.3889 - val_accuracy: 0.8307\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.0634 - accuracy: 0.8347 - val_loss: 0.3877 - val_accuracy: 0.8309\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0633 - accuracy: 0.8352 - val_loss: 0.3880 - val_accuracy: 0.8307\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0632 - accuracy: 0.8354 - val_loss: 0.3893 - val_accuracy: 0.8300\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0631 - accuracy: 0.8347 - val_loss: 0.3904 - val_accuracy: 0.8297\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0630 - accuracy: 0.8345 - val_loss: 0.3905 - val_accuracy: 0.8293\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0628 - accuracy: 0.8343 - val_loss: 0.3892 - val_accuracy: 0.8297\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.0627 - accuracy: 0.8349 - val_loss: 0.3873 - val_accuracy: 0.8302\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.0626 - accuracy: 0.8354 - val_loss: 0.3857 - val_accuracy: 0.8309\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.0625 - accuracy: 0.8354 - val_loss: 0.3851 - val_accuracy: 0.8312\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.0624 - accuracy: 0.8357 - val_loss: 0.3855 - val_accuracy: 0.8307\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.0623 - accuracy: 0.8357 - val_loss: 0.3864 - val_accuracy: 0.8300\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0622 - accuracy: 0.8355 - val_loss: 0.3868 - val_accuracy: 0.8300\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0621 - accuracy: 0.8353 - val_loss: 0.3864 - val_accuracy: 0.8300\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.0621 - accuracy: 0.8355 - val_loss: 0.3851 - val_accuracy: 0.8302\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.0620 - accuracy: 0.8357 - val_loss: 0.3837 - val_accuracy: 0.8305\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0619 - accuracy: 0.8358 - val_loss: 0.3829 - val_accuracy: 0.8302\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.0618 - accuracy: 0.8363 - val_loss: 0.3829 - val_accuracy: 0.8302\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.0617 - accuracy: 0.8365 - val_loss: 0.3834 - val_accuracy: 0.8297\n"
     ]
    }
   ],
   "source": [
    "best_term = 9 # 가장 성능이 좋은 term\n",
    "X_train, X_test, y_train,y_test = train_test_valid(f\"{best_term}year.csv\",valid=False)\n",
    "\n",
    "# 하이퍼 파라미터 지정\n",
    "learning_rate = 1e-4\n",
    "max_epoch = 100\n",
    "\n",
    "input_ = keras.layers.Input(shape = X_train.shape[1:])\n",
    "input2_ = keras.layers.Input(shape = (10*best_term,))\n",
    "hidden_layer1 = keras.layers.Dense(512, activation = \"selu\", kernel_initializer=lucun_init)(input_)\n",
    "hidden_layer2 = keras.layers.Dense(512, activation = \"selu\", kernel_initializer=lucun_init)(hidden_layer1)\n",
    "concat = keras.layers.concatenate([hidden_layer2, input2_])\n",
    "hidden_layer3 = keras.layers.Dense(256, activation = \"selu\", kernel_initializer=lucun_init)(concat)\n",
    "output_layer = keras.layers.Dense(1, activation = \"sigmoid\")(hidden_layer3)\n",
    "final_model = keras.Model(inputs = [input_, input2_], outputs = [output_layer])\n",
    "\n",
    "final_model.compile(loss=\"binary_crossentropy\", metrics=\"accuracy\", optimizer = keras.optimizers.Adam(lr=learning_rate))\n",
    "\n",
    "history = final_model.fit(x=[X_train,X_train[:,-10*best_term:]],y=y_train, epochs = max_epoch, \n",
    "                           validation_data = ((X_test,X_test[:,-10*best_term:]),y_test),\n",
    "                       class_weight = {0:0.1, 1:0.9}, batch_size = X_train.shape[0],validation_batch_size=X_test.shape[0],\n",
    "                                 callbacks=[tensorboard_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 에포크가 끝날 때 마다의 train, valid set의 loss, 평가 지표\n",
    "pd.DataFrame(history.history).plot(figsize = (8,5))\n",
    "plt.grid(True) # grid를 생성\n",
    "#plt.gca().set_ylim(0,1) # 수직출의 범위를 0~1 사이로 설정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = keras.models.load_model(\"final_mlp_best_model.h5\") # 저장된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.83\n",
      "precision : 0.39\n",
      "recall : 0.89\n",
      "roc : 0.85\n",
      "confusion-matrics\n",
      "[[3015  647]\n",
      " [  53  408]]\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, matrix, roc = get_score(X_test,y_test,best_term,final_model)\n",
    "print(\"accuracy : {:.2}\".format(accuracy))\n",
    "print(\"precision : {:.2}\".format(precision))\n",
    "print(\"recall : {:.2}\".format(recall))\n",
    "print(\"roc : {:.2}\".format(roc))\n",
    "print(\"confusion-matrics\")\n",
    "print(matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
